{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MikailINTech/DeepGo/blob/main/DeepGo_MD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzQXMDxpX0Eh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72ddedc7-8e27-4ccf-bcca-2095083d0f43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG-0AAA2Z4bz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae0b3d0-37fa-4c2f-c1cf-75efae7fff20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DeepGo\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/DeepGo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[1]*10**10"
      ],
      "metadata": {
        "id": "_hSBS4yXGfbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVcHkv8KkaCB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers \n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D,Reshape\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "\n",
        "import golois\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/DeepGo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IO4CwDqEyDEC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86d9437f-f6e6-4dbd-e171-72d1dd9f0d35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "getValidation\n"
          ]
        }
      ],
      "source": [
        "planes = 31\n",
        "moves = 361\n",
        "N = 10000\n",
        "epochs = 50\n",
        "batch = 64\n",
        "filters = 256\n",
        "expand = filters*4\n",
        "\n",
        "input_data = np.random.randint(2, size=(N, 19, 19, planes))\n",
        "input_data = input_data.astype ('float32')\n",
        "\n",
        "policy = np.random.randint(moves, size=(N,))\n",
        "policy = keras.utils.to_categorical (policy)\n",
        "\n",
        "value = np.random.randint(2, size=(N,))\n",
        "value = value.astype ('float32')\n",
        "\n",
        "end = np.random.randint(2, size=(N, 19, 19, 2))\n",
        "end = end.astype ('float32')\n",
        "\n",
        "groups = np.zeros((N, 19, 19, 1))\n",
        "groups = groups.astype ('float32')\n",
        "\n",
        "print (\"getValidation\", flush = True)\n",
        "golois.getValidation (input_data, policy, value, end)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnzO1Ud3JaF2"
      },
      "outputs": [],
      "source": [
        "def SE_Block(t,filters,ratio=4):\n",
        "  filters=t.shape[-1]\n",
        "  se_shape= (1,1,filters)\n",
        "  se = layers.GlobalAveragePooling2D()(t)\n",
        "  se = layers.Reshape(se_shape)(se)\n",
        "  se = layers.Dense(filters // ratio,use_bias=False)(se)\n",
        "  se = layers.Activation('ReLU')(se)\n",
        "  se = layers.Dense(filters, use_bias=False)(se)\n",
        "  se = layers.Activation(tf.keras.activations.swish)(se)\n",
        "  x = layers.multiply([t,se])\n",
        "\n",
        "  return t\n",
        "\n",
        "\n",
        "def bottleneck_block(x, kernel_size,expand, squeeze,activation=tf.keras.activations.swish,SE=True):\n",
        "    m = layers.Conv2D(expand, (1,1), kernel_regularizer=regularizers.l2(0.0001), use_bias = False)(x)\n",
        "    m = layers.Activation(activation)(m)\n",
        "    m = layers.BatchNormalization()(m)\n",
        "    m = layers.Activation(activation)(m)\n",
        "\n",
        "    m1= layers.DepthwiseConv2D((kernel_size, kernel_size), padding='same', kernel_regularizer=regularizers.l2(0.0001), use_bias = False)(m)\n",
        "    m2= layers.DepthwiseConv2D((3,3), padding='same',kernel_regularizer=regularizers.l2(0.0001), use_bias = False)(m)\n",
        "    m3= layers.DepthwiseConv2D((5,5),padding='same',kernel_regularizer=regularizers.l2(0.0001), use_bias = False)(m)\n",
        "\n",
        "    m1 = layers.BatchNormalization()(m1)\n",
        "    m1 = layers.Activation(activation)(m1)\n",
        "    m2 = layers.BatchNormalization()(m2)\n",
        "    m2 = layers.Activation(activation)(m2)\n",
        "    m3 = layers.BatchNormalization()(m3)\n",
        "    m3 = layers.Activation(activation)(m3)\n",
        "    m = layers.Concatenate(axis=-1)([m1,m2,m3])\n",
        "    if SE:\n",
        "      m = SE_Block(m,expand)\n",
        "    m = layers.Conv2D(squeeze, (1,1), kernel_regularizer=regularizers.l2(0.0001), use_bias = False)(m)\n",
        "    m = layers.BatchNormalization()(m)\n",
        "    if squeeze == x.shape[-1]:\n",
        "      m = layers.Add()([m, x])\n",
        "    return m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibMxJFY0yEyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5a5dfcc-4a41-43ae-be8e-8ee5d3bad0c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_20\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " board (InputLayer)             [(None, 19, 19, 31)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " conv2d_602 (Conv2D)            (None, 19, 19, 16)   4480        ['board[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_603 (Conv2D)            (None, 19, 19, 16)   256         ['conv2d_602[0][0]']             \n",
            "                                                                                                  \n",
            " activation_1661 (Activation)   (None, 19, 19, 16)   0           ['conv2d_603[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1251 (Batc  (None, 19, 19, 16)  64          ['activation_1661[0][0]']        \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1662 (Activation)   (None, 19, 19, 16)   0           ['batch_normalization_1251[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_735 (Depthwis  (None, 19, 19, 16)  144         ['activation_1662[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_736 (Depthwis  (None, 19, 19, 16)  144         ['activation_1662[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_737 (Depthwis  (None, 19, 19, 16)  400         ['activation_1662[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_1252 (Batc  (None, 19, 19, 16)  64          ['depthwise_conv2d_735[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1253 (Batc  (None, 19, 19, 16)  64          ['depthwise_conv2d_736[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1254 (Batc  (None, 19, 19, 16)  64          ['depthwise_conv2d_737[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1663 (Activation)   (None, 19, 19, 16)   0           ['batch_normalization_1252[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1664 (Activation)   (None, 19, 19, 16)   0           ['batch_normalization_1253[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1665 (Activation)   (None, 19, 19, 16)   0           ['batch_normalization_1254[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " concatenate_245 (Concatenate)  (None, 19, 19, 48)   0           ['activation_1663[0][0]',        \n",
            "                                                                  'activation_1664[0][0]',        \n",
            "                                                                  'activation_1665[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_604 (Conv2D)            (None, 19, 19, 16)   768         ['concatenate_245[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_1255 (Batc  (None, 19, 19, 16)  64          ['conv2d_604[0][0]']             \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " add_122 (Add)                  (None, 19, 19, 16)   0           ['batch_normalization_1255[0][0]'\n",
            "                                                                 , 'conv2d_602[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_605 (Conv2D)            (None, 19, 19, 60)   960         ['add_122[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1668 (Activation)   (None, 19, 19, 60)   0           ['conv2d_605[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1256 (Batc  (None, 19, 19, 60)  240         ['activation_1668[0][0]']        \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1669 (Activation)   (None, 19, 19, 60)   0           ['batch_normalization_1256[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_738 (Depthwis  (None, 19, 19, 60)  540         ['activation_1669[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_739 (Depthwis  (None, 19, 19, 60)  540         ['activation_1669[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_740 (Depthwis  (None, 19, 19, 60)  1500        ['activation_1669[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_1257 (Batc  (None, 19, 19, 60)  240         ['depthwise_conv2d_738[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1258 (Batc  (None, 19, 19, 60)  240         ['depthwise_conv2d_739[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1259 (Batc  (None, 19, 19, 60)  240         ['depthwise_conv2d_740[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1670 (Activation)   (None, 19, 19, 60)   0           ['batch_normalization_1257[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1671 (Activation)   (None, 19, 19, 60)   0           ['batch_normalization_1258[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1672 (Activation)   (None, 19, 19, 60)   0           ['batch_normalization_1259[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " concatenate_246 (Concatenate)  (None, 19, 19, 180)  0           ['activation_1670[0][0]',        \n",
            "                                                                  'activation_1671[0][0]',        \n",
            "                                                                  'activation_1672[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_606 (Conv2D)            (None, 19, 19, 20)   3600        ['concatenate_246[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_1260 (Batc  (None, 19, 19, 20)  80          ['conv2d_606[0][0]']             \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " conv2d_607 (Conv2D)            (None, 19, 19, 80)   1600        ['batch_normalization_1260[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1673 (Activation)   (None, 19, 19, 80)   0           ['conv2d_607[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1261 (Batc  (None, 19, 19, 80)  320         ['activation_1673[0][0]']        \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1674 (Activation)   (None, 19, 19, 80)   0           ['batch_normalization_1261[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_741 (Depthwis  (None, 19, 19, 80)  720         ['activation_1674[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_742 (Depthwis  (None, 19, 19, 80)  720         ['activation_1674[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_743 (Depthwis  (None, 19, 19, 80)  2000        ['activation_1674[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_1262 (Batc  (None, 19, 19, 80)  320         ['depthwise_conv2d_741[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1263 (Batc  (None, 19, 19, 80)  320         ['depthwise_conv2d_742[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1264 (Batc  (None, 19, 19, 80)  320         ['depthwise_conv2d_743[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1675 (Activation)   (None, 19, 19, 80)   0           ['batch_normalization_1262[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1676 (Activation)   (None, 19, 19, 80)   0           ['batch_normalization_1263[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1677 (Activation)   (None, 19, 19, 80)   0           ['batch_normalization_1264[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " concatenate_247 (Concatenate)  (None, 19, 19, 240)  0           ['activation_1675[0][0]',        \n",
            "                                                                  'activation_1676[0][0]',        \n",
            "                                                                  'activation_1677[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_608 (Conv2D)            (None, 19, 19, 20)   4800        ['concatenate_247[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_1265 (Batc  (None, 19, 19, 20)  80          ['conv2d_608[0][0]']             \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " add_123 (Add)                  (None, 19, 19, 20)   0           ['batch_normalization_1265[0][0]'\n",
            "                                                                 , 'batch_normalization_1260[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv2d_609 (Conv2D)            (None, 19, 19, 90)   1800        ['add_123[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1678 (Activation)   (None, 19, 19, 90)   0           ['conv2d_609[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1266 (Batc  (None, 19, 19, 90)  360         ['activation_1678[0][0]']        \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1679 (Activation)   (None, 19, 19, 90)   0           ['batch_normalization_1266[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_744 (Depthwis  (None, 19, 19, 90)  2250        ['activation_1679[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_745 (Depthwis  (None, 19, 19, 90)  810         ['activation_1679[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_746 (Depthwis  (None, 19, 19, 90)  2250        ['activation_1679[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_1267 (Batc  (None, 19, 19, 90)  360         ['depthwise_conv2d_744[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1268 (Batc  (None, 19, 19, 90)  360         ['depthwise_conv2d_745[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1269 (Batc  (None, 19, 19, 90)  360         ['depthwise_conv2d_746[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1680 (Activation)   (None, 19, 19, 90)   0           ['batch_normalization_1267[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1681 (Activation)   (None, 19, 19, 90)   0           ['batch_normalization_1268[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1682 (Activation)   (None, 19, 19, 90)   0           ['batch_normalization_1269[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " concatenate_248 (Concatenate)  (None, 19, 19, 270)  0           ['activation_1680[0][0]',        \n",
            "                                                                  'activation_1681[0][0]',        \n",
            "                                                                  'activation_1682[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_610 (Conv2D)            (None, 19, 19, 40)   10800       ['concatenate_248[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_1270 (Batc  (None, 19, 19, 40)  160         ['conv2d_610[0][0]']             \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " conv2d_611 (Conv2D)            (None, 19, 19, 240)  9600        ['batch_normalization_1270[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1683 (Activation)   (None, 19, 19, 240)  0           ['conv2d_611[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1271 (Batc  (None, 19, 19, 240)  960        ['activation_1683[0][0]']        \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1684 (Activation)   (None, 19, 19, 240)  0           ['batch_normalization_1271[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_747 (Depthwis  (None, 19, 19, 240)  6000       ['activation_1684[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_748 (Depthwis  (None, 19, 19, 240)  2160       ['activation_1684[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_749 (Depthwis  (None, 19, 19, 240)  6000       ['activation_1684[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_1272 (Batc  (None, 19, 19, 240)  960        ['depthwise_conv2d_747[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1273 (Batc  (None, 19, 19, 240)  960        ['depthwise_conv2d_748[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1274 (Batc  (None, 19, 19, 240)  960        ['depthwise_conv2d_749[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1685 (Activation)   (None, 19, 19, 240)  0           ['batch_normalization_1272[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1686 (Activation)   (None, 19, 19, 240)  0           ['batch_normalization_1273[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1687 (Activation)   (None, 19, 19, 240)  0           ['batch_normalization_1274[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " concatenate_249 (Concatenate)  (None, 19, 19, 720)  0           ['activation_1685[0][0]',        \n",
            "                                                                  'activation_1686[0][0]',        \n",
            "                                                                  'activation_1687[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_612 (Conv2D)            (None, 19, 19, 60)   43200       ['concatenate_249[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_1275 (Batc  (None, 19, 19, 60)  240         ['conv2d_612[0][0]']             \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " conv2d_613 (Conv2D)            (None, 19, 19, 240)  14400       ['batch_normalization_1275[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1690 (Activation)   (None, 19, 19, 240)  0           ['conv2d_613[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1276 (Batc  (None, 19, 19, 240)  960        ['activation_1690[0][0]']        \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1691 (Activation)   (None, 19, 19, 240)  0           ['batch_normalization_1276[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_750 (Depthwis  (None, 19, 19, 240)  6000       ['activation_1691[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_751 (Depthwis  (None, 19, 19, 240)  2160       ['activation_1691[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_752 (Depthwis  (None, 19, 19, 240)  6000       ['activation_1691[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_1277 (Batc  (None, 19, 19, 240)  960        ['depthwise_conv2d_750[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1278 (Batc  (None, 19, 19, 240)  960        ['depthwise_conv2d_751[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1279 (Batc  (None, 19, 19, 240)  960        ['depthwise_conv2d_752[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1692 (Activation)   (None, 19, 19, 240)  0           ['batch_normalization_1277[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1693 (Activation)   (None, 19, 19, 240)  0           ['batch_normalization_1278[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1694 (Activation)   (None, 19, 19, 240)  0           ['batch_normalization_1279[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " concatenate_250 (Concatenate)  (None, 19, 19, 720)  0           ['activation_1692[0][0]',        \n",
            "                                                                  'activation_1693[0][0]',        \n",
            "                                                                  'activation_1694[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_614 (Conv2D)            (None, 19, 19, 60)   43200       ['concatenate_250[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_1280 (Batc  (None, 19, 19, 60)  240         ['conv2d_614[0][0]']             \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " add_124 (Add)                  (None, 19, 19, 60)   0           ['batch_normalization_1280[0][0]'\n",
            "                                                                 , 'batch_normalization_1275[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv2d_615 (Conv2D)            (None, 19, 19, 120)  7200        ['add_124[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1697 (Activation)   (None, 19, 19, 120)  0           ['conv2d_615[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1281 (Batc  (None, 19, 19, 120)  480        ['activation_1697[0][0]']        \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1698 (Activation)   (None, 19, 19, 120)  0           ['batch_normalization_1281[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_753 (Depthwis  (None, 19, 19, 120)  3000       ['activation_1698[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_754 (Depthwis  (None, 19, 19, 120)  1080       ['activation_1698[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_755 (Depthwis  (None, 19, 19, 120)  3000       ['activation_1698[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_1282 (Batc  (None, 19, 19, 120)  480        ['depthwise_conv2d_753[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1283 (Batc  (None, 19, 19, 120)  480        ['depthwise_conv2d_754[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1284 (Batc  (None, 19, 19, 120)  480        ['depthwise_conv2d_755[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1699 (Activation)   (None, 19, 19, 120)  0           ['batch_normalization_1282[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1700 (Activation)   (None, 19, 19, 120)  0           ['batch_normalization_1283[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1701 (Activation)   (None, 19, 19, 120)  0           ['batch_normalization_1284[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " concatenate_251 (Concatenate)  (None, 19, 19, 360)  0           ['activation_1699[0][0]',        \n",
            "                                                                  'activation_1700[0][0]',        \n",
            "                                                                  'activation_1701[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_616 (Conv2D)            (None, 19, 19, 40)   14400       ['concatenate_251[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_1285 (Batc  (None, 19, 19, 40)  160         ['conv2d_616[0][0]']             \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " conv2d_617 (Conv2D)            (None, 19, 19, 240)  9600        ['batch_normalization_1285[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1704 (Activation)   (None, 19, 19, 240)  0           ['conv2d_617[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1286 (Batc  (None, 19, 19, 240)  960        ['activation_1704[0][0]']        \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1705 (Activation)   (None, 19, 19, 240)  0           ['batch_normalization_1286[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_756 (Depthwis  (None, 19, 19, 240)  2160       ['activation_1705[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_757 (Depthwis  (None, 19, 19, 240)  2160       ['activation_1705[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_758 (Depthwis  (None, 19, 19, 240)  6000       ['activation_1705[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_1287 (Batc  (None, 19, 19, 240)  960        ['depthwise_conv2d_756[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1288 (Batc  (None, 19, 19, 240)  960        ['depthwise_conv2d_757[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1289 (Batc  (None, 19, 19, 240)  960        ['depthwise_conv2d_758[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1706 (Activation)   (None, 19, 19, 240)  0           ['batch_normalization_1287[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1707 (Activation)   (None, 19, 19, 240)  0           ['batch_normalization_1288[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1708 (Activation)   (None, 19, 19, 240)  0           ['batch_normalization_1289[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " concatenate_252 (Concatenate)  (None, 19, 19, 720)  0           ['activation_1706[0][0]',        \n",
            "                                                                  'activation_1707[0][0]',        \n",
            "                                                                  'activation_1708[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_618 (Conv2D)            (None, 19, 19, 60)   43200       ['concatenate_252[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_1290 (Batc  (None, 19, 19, 60)  240         ['conv2d_618[0][0]']             \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " conv2d_619 (Conv2D)            (None, 19, 19, 240)  14400       ['batch_normalization_1290[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1711 (Activation)   (None, 19, 19, 240)  0           ['conv2d_619[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1291 (Batc  (None, 19, 19, 240)  960        ['activation_1711[0][0]']        \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1712 (Activation)   (None, 19, 19, 240)  0           ['batch_normalization_1291[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_759 (Depthwis  (None, 19, 19, 240)  2160       ['activation_1712[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_760 (Depthwis  (None, 19, 19, 240)  2160       ['activation_1712[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_761 (Depthwis  (None, 19, 19, 240)  6000       ['activation_1712[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_1292 (Batc  (None, 19, 19, 240)  960        ['depthwise_conv2d_759[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1293 (Batc  (None, 19, 19, 240)  960        ['depthwise_conv2d_760[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1294 (Batc  (None, 19, 19, 240)  960        ['depthwise_conv2d_761[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1713 (Activation)   (None, 19, 19, 240)  0           ['batch_normalization_1292[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1714 (Activation)   (None, 19, 19, 240)  0           ['batch_normalization_1293[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1715 (Activation)   (None, 19, 19, 240)  0           ['batch_normalization_1294[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " concatenate_253 (Concatenate)  (None, 19, 19, 720)  0           ['activation_1713[0][0]',        \n",
            "                                                                  'activation_1714[0][0]',        \n",
            "                                                                  'activation_1715[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_620 (Conv2D)            (None, 19, 19, 60)   43200       ['concatenate_253[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_1295 (Batc  (None, 19, 19, 60)  240         ['conv2d_620[0][0]']             \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " add_125 (Add)                  (None, 19, 19, 60)   0           ['batch_normalization_1295[0][0]'\n",
            "                                                                 , 'batch_normalization_1290[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv2d_621 (Conv2D)            (None, 19, 19, 120)  7200        ['add_125[0][0]']                \n",
            "                                                                                                  \n",
            " activation_1718 (Activation)   (None, 19, 19, 120)  0           ['conv2d_621[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1296 (Batc  (None, 19, 19, 120)  480        ['activation_1718[0][0]']        \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1719 (Activation)   (None, 19, 19, 120)  0           ['batch_normalization_1296[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_762 (Depthwis  (None, 19, 19, 120)  3000       ['activation_1719[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_763 (Depthwis  (None, 19, 19, 120)  1080       ['activation_1719[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_764 (Depthwis  (None, 19, 19, 120)  3000       ['activation_1719[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_1297 (Batc  (None, 19, 19, 120)  480        ['depthwise_conv2d_762[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1298 (Batc  (None, 19, 19, 120)  480        ['depthwise_conv2d_763[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1299 (Batc  (None, 19, 19, 120)  480        ['depthwise_conv2d_764[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1720 (Activation)   (None, 19, 19, 120)  0           ['batch_normalization_1297[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1721 (Activation)   (None, 19, 19, 120)  0           ['batch_normalization_1298[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1722 (Activation)   (None, 19, 19, 120)  0           ['batch_normalization_1299[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " concatenate_254 (Concatenate)  (None, 19, 19, 360)  0           ['activation_1720[0][0]',        \n",
            "                                                                  'activation_1721[0][0]',        \n",
            "                                                                  'activation_1722[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_622 (Conv2D)            (None, 19, 19, 50)   18000       ['concatenate_254[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_1300 (Batc  (None, 19, 19, 50)  200         ['conv2d_622[0][0]']             \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " conv2d_623 (Conv2D)            (None, 19, 19, 320)  16000       ['batch_normalization_1300[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1725 (Activation)   (None, 19, 19, 320)  0           ['conv2d_623[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1301 (Batc  (None, 19, 19, 320)  1280       ['activation_1725[0][0]']        \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1726 (Activation)   (None, 19, 19, 320)  0           ['batch_normalization_1301[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_765 (Depthwis  (None, 19, 19, 320)  8000       ['activation_1726[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_766 (Depthwis  (None, 19, 19, 320)  2880       ['activation_1726[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_767 (Depthwis  (None, 19, 19, 320)  8000       ['activation_1726[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_1302 (Batc  (None, 19, 19, 320)  1280       ['depthwise_conv2d_765[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1303 (Batc  (None, 19, 19, 320)  1280       ['depthwise_conv2d_766[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1304 (Batc  (None, 19, 19, 320)  1280       ['depthwise_conv2d_767[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1727 (Activation)   (None, 19, 19, 320)  0           ['batch_normalization_1302[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1728 (Activation)   (None, 19, 19, 320)  0           ['batch_normalization_1303[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1729 (Activation)   (None, 19, 19, 320)  0           ['batch_normalization_1304[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " concatenate_255 (Concatenate)  (None, 19, 19, 960)  0           ['activation_1727[0][0]',        \n",
            "                                                                  'activation_1728[0][0]',        \n",
            "                                                                  'activation_1729[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_624 (Conv2D)            (None, 19, 19, 80)   76800       ['concatenate_255[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_1305 (Batc  (None, 19, 19, 80)  320         ['conv2d_624[0][0]']             \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " conv2d_625 (Conv2D)            (None, 19, 19, 560)  44800       ['batch_normalization_1305[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1732 (Activation)   (None, 19, 19, 560)  0           ['conv2d_625[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1306 (Batc  (None, 19, 19, 560)  2240       ['activation_1732[0][0]']        \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1733 (Activation)   (None, 19, 19, 560)  0           ['batch_normalization_1306[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_768 (Depthwis  (None, 19, 19, 560)  14000      ['activation_1733[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_769 (Depthwis  (None, 19, 19, 560)  5040       ['activation_1733[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_770 (Depthwis  (None, 19, 19, 560)  14000      ['activation_1733[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_1307 (Batc  (None, 19, 19, 560)  2240       ['depthwise_conv2d_768[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1308 (Batc  (None, 19, 19, 560)  2240       ['depthwise_conv2d_769[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1309 (Batc  (None, 19, 19, 560)  2240       ['depthwise_conv2d_770[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1734 (Activation)   (None, 19, 19, 560)  0           ['batch_normalization_1307[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1735 (Activation)   (None, 19, 19, 560)  0           ['batch_normalization_1308[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1736 (Activation)   (None, 19, 19, 560)  0           ['batch_normalization_1309[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " concatenate_256 (Concatenate)  (None, 19, 19, 1680  0           ['activation_1734[0][0]',        \n",
            "                                )                                 'activation_1735[0][0]',        \n",
            "                                                                  'activation_1736[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_626 (Conv2D)            (None, 19, 19, 90)   151200      ['concatenate_256[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_1310 (Batc  (None, 19, 19, 90)  360         ['conv2d_626[0][0]']             \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " conv2d_627 (Conv2D)            (None, 19, 19, 560)  50400       ['batch_normalization_1310[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1739 (Activation)   (None, 19, 19, 560)  0           ['conv2d_627[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1311 (Batc  (None, 19, 19, 560)  2240       ['activation_1739[0][0]']        \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1740 (Activation)   (None, 19, 19, 560)  0           ['batch_normalization_1311[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " depthwise_conv2d_771 (Depthwis  (None, 19, 19, 560)  14000      ['activation_1740[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_772 (Depthwis  (None, 19, 19, 560)  5040       ['activation_1740[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " depthwise_conv2d_773 (Depthwis  (None, 19, 19, 560)  14000      ['activation_1740[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_1312 (Batc  (None, 19, 19, 560)  2240       ['depthwise_conv2d_771[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1313 (Batc  (None, 19, 19, 560)  2240       ['depthwise_conv2d_772[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " batch_normalization_1314 (Batc  (None, 19, 19, 560)  2240       ['depthwise_conv2d_773[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1741 (Activation)   (None, 19, 19, 560)  0           ['batch_normalization_1312[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1742 (Activation)   (None, 19, 19, 560)  0           ['batch_normalization_1313[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " activation_1743 (Activation)   (None, 19, 19, 560)  0           ['batch_normalization_1314[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " concatenate_257 (Concatenate)  (None, 19, 19, 1680  0           ['activation_1741[0][0]',        \n",
            "                                )                                 'activation_1742[0][0]',        \n",
            "                                                                  'activation_1743[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_628 (Conv2D)            (None, 19, 19, 90)   151200      ['concatenate_257[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_1315 (Batc  (None, 19, 19, 90)  360         ['conv2d_628[0][0]']             \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " add_126 (Add)                  (None, 19, 19, 90)   0           ['batch_normalization_1315[0][0]'\n",
            "                                                                 , 'batch_normalization_1310[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " conv2d_629 (Conv2D)            (None, 19, 19, 90)   8100        ['add_126[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_1316 (Batc  (None, 19, 19, 90)  360         ['conv2d_629[0][0]']             \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " activation_1746 (Activation)   (None, 19, 19, 90)   0           ['batch_normalization_1316[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " conv2d_630 (Conv2D)            (None, 19, 19, 1)    90          ['activation_1746[0][0]']        \n",
            "                                                                                                  \n",
            " activation_1747 (Activation)   (None, 19, 19, 1)    0           ['conv2d_630[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_632 (Conv2D)            (None, 19, 19, 1)    90          ['add_126[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_631 (Conv2D)            (None, 19, 19, 1)    1           ['activation_1747[0][0]']        \n",
            "                                                                                                  \n",
            " activation_1748 (Activation)   (None, 19, 19, 1)    0           ['conv2d_632[0][0]']             \n",
            "                                                                                                  \n",
            " flatten_26 (Flatten)           (None, 361)          0           ['conv2d_631[0][0]']             \n",
            "                                                                                                  \n",
            " global_average_pooling2d_209 (  (None, 1)           0           ['activation_1748[0][0]']        \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " policy (Activation)            (None, 361)          0           ['flatten_26[0][0]']             \n",
            "                                                                                                  \n",
            " value (Dense)                  (None, 1)            2           ['global_average_pooling2d_209[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,004,725\n",
            "Trainable params: 980,085\n",
            "Non-trainable params: 24,640\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def buildModel(batch,epochs,filters,expand):\n",
        "  input = keras.Input(shape=(19, 19, planes), name='board')\n",
        "  x = layers.Conv2D(16, (3, 3), padding='same',activation=tf.keras.activations.swish)(input)\n",
        "\n",
        "  x = bottleneck_block(x,3,expand=16,squeeze=16,activation='ReLU')\n",
        "  x = bottleneck_block(x,3,expand=60,squeeze=20,activation='ReLU',SE=False)\n",
        "  x = bottleneck_block(x,3,expand=80,squeeze=20,activation='ReLU',SE=False)\n",
        "  x = bottleneck_block(x,5,expand=90,squeeze=40,activation='ReLU',SE=False)\n",
        "  x = bottleneck_block(x,5,expand=240,squeeze=60)\n",
        "  x = bottleneck_block(x,5,expand=240,squeeze=60)\n",
        "  x = bottleneck_block(x,5,expand=120,squeeze=40)\n",
        "  x = bottleneck_block(x,3,expand=240,squeeze=60)\n",
        "  x = bottleneck_block(x,3,expand=240,squeeze=60)\n",
        "  x = bottleneck_block(x,5,expand=120,squeeze=50)\n",
        "  x = bottleneck_block(x,5,expand=320,squeeze=80)\n",
        "  x = bottleneck_block(x,5,expand=560,squeeze=90)\n",
        "  x = bottleneck_block(x,5,expand=560,squeeze=90)\n",
        "\n",
        "  policy_head = layers.Conv2D(90,1, 1, padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "  policy_head = layers.BatchNormalization()(policy_head)\n",
        "  policy_head = layers.Activation(tf.keras.activations.swish)(policy_head)\n",
        "  #policy_head = layers.AveragePooling2D()(policy_head)\n",
        "  policy_head = layers.Conv2D(1, 1, padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(policy_head)\n",
        "  policy_head = layers.Activation(tf.keras.activations.swish)(policy_head)\n",
        "  policy_head = layers.Conv2D(1, 1, padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(policy_head)\n",
        "  policy_head = layers.Flatten()(policy_head)\n",
        "  policy_head = layers.Activation('softmax', name='policy')(policy_head)\n",
        "  \n",
        "  \n",
        "  \n",
        "  value_head = layers.Conv2D(1, 1, padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "  value_head = layers.Activation('ReLU')(value_head)\n",
        "  value_head = layers.GlobalAveragePooling2D()(value_head)\n",
        "  value_head = layers.Dense(1, activation='sigmoid', name='value', kernel_regularizer=regularizers.l2(0.0001))(value_head)\n",
        "\n",
        "  #policy_head = layers.Conv2D(120,1, 1, padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "  #policy_head = layers.BatchNormalization()(policy_head)\n",
        "  #policy_head = layers.Activation(tf.keras.activations.swish)(policy_head)\n",
        "  #policy_head = layers.AveragePooling2D(pool_size=(19, 19), strides=None, padding=\"same\")(policy_head)\n",
        "  #policy_head = layers.Conv2D(480,1, 1, padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(policy_head)\n",
        "  #policy_head = layers.Activation(tf.keras.activations.swish)(policy_head)\n",
        "  #policy_head = layers.Conv2D(19*19,1, 1, padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(policy_head)\n",
        "  #policy_head = layers.Flatten()(policy_head)\n",
        "  #policy_head = layers.Activation('softmax', name='policy')(policy_head)\n",
        "  \n",
        "  \n",
        "  \n",
        "  #value_head = layers.Conv2D(120,1, 1, padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(x)\n",
        "  #value_head = layers.BatchNormalization()(value_head)\n",
        "  #value_head = layers.Activation('ReLU')(value_head)\n",
        "  #value_head = layers.AveragePooling2D(pool_size=(19, 19), strides=None, padding=\"same\")(value_head)\n",
        "  #value_head = layers.Conv2D(480,1, 1, padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(value_head)\n",
        "  #value_head = layers.Activation(tf.keras.activations.swish)(value_head)\n",
        "  #value_head = layers.Conv2D(1,1, 1, padding='same', use_bias = False, kernel_regularizer=regularizers.l2(0.0001))(value_head)\n",
        "  #value_head = layers.Flatten()(value_head)\n",
        "  #value_head = layers.Dense(1, activation='sigmoid', name='value', kernel_regularizer=regularizers.l2(0.0001))(value_head)\n",
        "  \n",
        "  model = keras.Model(inputs=input, outputs=[policy_head, value_head])\n",
        "\n",
        "  return model\n",
        "\n",
        "model=buildModel(batch,epochs,filters,expand)\n",
        "\n",
        "model.summary ()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=tf.keras.optimizers.Nadam(\n",
        "    learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Nadam\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "vyDntVHp7rwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vvNPEa2jZIn"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=optimizer,\n",
        "              loss={'policy': 'categorical_crossentropy', 'value': 'binary_crossentropy'},\n",
        "              loss_weights={'policy' : 1.0, 'value' : 1.0},\n",
        "              metrics={'policy': 'categorical_accuracy', 'value': 'mse'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDHhgN5GoJXD"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "from keras import backend as K\n",
        "filepath = '/content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, \n",
        "                             monitor='policy_loss',\n",
        "                             verbose=1, \n",
        "                             save_best_only=True,\n",
        "                             mode='min')\n",
        "callbacks = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qTK7a-VLZ4p2",
        "outputId": "7216d8bf-8ef1-431c-84dd-6ead7f55696a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_acc=[]\n",
        "history_lr=[]\n",
        "history_MSE=[]"
      ],
      "metadata": {
        "id": "did4lXucn9En"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(threshold=np.inf)"
      ],
      "metadata": {
        "id": "E0gjsxMwvF77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5E1StX6yX-U",
        "outputId": "a0f138d4-62c6-49f2-af4a-5664941e47d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1\n",
            "157/157 [==============================] - ETA: 0s - loss: 6.7903 - policy_loss: 5.8585 - value_loss: 0.7005 - policy_categorical_accuracy: 0.0034 - value_mse: 0.1227\n",
            "Epoch 00001: policy_loss improved from inf to 5.85848, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r157/157 [==============================] - 54s 230ms/step - loss: 6.7903 - policy_loss: 5.8585 - value_loss: 0.7005 - policy_categorical_accuracy: 0.0034 - value_mse: 0.1227\n",
            "epoch 2\n",
            "157/157 [==============================] - ETA: 0s - loss: 6.4611 - policy_loss: 5.5428 - value_loss: 0.6932 - policy_categorical_accuracy: 0.0173 - value_mse: 0.1189\n",
            "Epoch 00001: policy_loss improved from 5.85848 to 5.54276, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 6.4611 - policy_loss: 5.5428 - value_loss: 0.6932 - policy_categorical_accuracy: 0.0173 - value_mse: 0.1189\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 6.80437 | Policy loss 5.88974 | Value loss 0.69277 | Policy acc 0.00110 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 3\n",
            "157/157 [==============================] - ETA: 0s - loss: 5.7991 - policy_loss: 4.8885 - value_loss: 0.6927 - policy_categorical_accuracy: 0.0603 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss improved from 5.54276 to 4.88850, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 229ms/step - loss: 5.7991 - policy_loss: 4.8885 - value_loss: 0.6927 - policy_categorical_accuracy: 0.0603 - value_mse: 0.1177\n",
            "epoch 4\n",
            "157/157 [==============================] - ETA: 0s - loss: 5.6138 - policy_loss: 4.7108 - value_loss: 0.6931 - policy_categorical_accuracy: 0.0797 - value_mse: 0.1199\n",
            "Epoch 00001: policy_loss improved from 4.88850 to 4.71079, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 229ms/step - loss: 5.6138 - policy_loss: 4.7108 - value_loss: 0.6931 - policy_categorical_accuracy: 0.0797 - value_mse: 0.1199\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 5.64095 | Policy loss 4.74212 | Value loss 0.69277 | Policy acc 0.08600 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 5\n",
            "157/157 [==============================] - ETA: 0s - loss: 5.4280 - policy_loss: 4.5325 - value_loss: 0.6932 - policy_categorical_accuracy: 0.1174 - value_mse: 0.1186\n",
            "Epoch 00001: policy_loss improved from 4.71079 to 4.53249, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 229ms/step - loss: 5.4280 - policy_loss: 4.5325 - value_loss: 0.6932 - policy_categorical_accuracy: 0.1174 - value_mse: 0.1186\n",
            "epoch 6\n",
            "157/157 [==============================] - ETA: 0s - loss: 5.1592 - policy_loss: 4.2703 - value_loss: 0.6930 - policy_categorical_accuracy: 0.1551 - value_mse: 0.1197\n",
            "Epoch 00001: policy_loss improved from 4.53249 to 4.27035, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 5.1592 - policy_loss: 4.2703 - value_loss: 0.6930 - policy_categorical_accuracy: 0.1551 - value_mse: 0.1197\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 6.59083 | Policy loss 5.70453 | Value loss 0.69278 | Policy acc 0.12390 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 7\n",
            "157/157 [==============================] - ETA: 0s - loss: 4.8156 - policy_loss: 3.9312 - value_loss: 0.6928 - policy_categorical_accuracy: 0.1837 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss improved from 4.27035 to 3.93125, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 4.8156 - policy_loss: 3.9312 - value_loss: 0.6928 - policy_categorical_accuracy: 0.1837 - value_mse: 0.1177\n",
            "epoch 8\n",
            "157/157 [==============================] - ETA: 0s - loss: 4.5456 - policy_loss: 3.6660 - value_loss: 0.6928 - policy_categorical_accuracy: 0.2128 - value_mse: 0.1178\n",
            "Epoch 00001: policy_loss improved from 3.93125 to 3.66605, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 4.5456 - policy_loss: 3.6660 - value_loss: 0.6928 - policy_categorical_accuracy: 0.2128 - value_mse: 0.1178\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 5.07681 | Policy loss 4.19993 | Value loss 0.69275 | Policy acc 0.18310 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 9\n",
            "157/157 [==============================] - ETA: 0s - loss: 4.3800 - policy_loss: 3.5056 - value_loss: 0.6927 - policy_categorical_accuracy: 0.2338 - value_mse: 0.1174\n",
            "Epoch 00001: policy_loss improved from 3.66605 to 3.50564, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 4.3800 - policy_loss: 3.5056 - value_loss: 0.6927 - policy_categorical_accuracy: 0.2338 - value_mse: 0.1174\n",
            "epoch 10\n",
            "157/157 [==============================] - ETA: 0s - loss: 4.2664 - policy_loss: 3.3972 - value_loss: 0.6929 - policy_categorical_accuracy: 0.2482 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss improved from 3.50564 to 3.39722, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 229ms/step - loss: 4.2664 - policy_loss: 3.3972 - value_loss: 0.6929 - policy_categorical_accuracy: 0.2482 - value_mse: 0.1182\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 4.39659 | Policy loss 3.53013 | Value loss 0.69276 | Policy acc 0.23450 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 11\n",
            "157/157 [==============================] - ETA: 0s - loss: 4.1723 - policy_loss: 3.3077 - value_loss: 0.6931 - policy_categorical_accuracy: 0.2588 - value_mse: 0.1186\n",
            "Epoch 00001: policy_loss improved from 3.39722 to 3.30769, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 4.1723 - policy_loss: 3.3077 - value_loss: 0.6931 - policy_categorical_accuracy: 0.2588 - value_mse: 0.1186\n",
            "epoch 12\n",
            "157/157 [==============================] - ETA: 0s - loss: 4.1057 - policy_loss: 3.2463 - value_loss: 0.6927 - policy_categorical_accuracy: 0.2591 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss improved from 3.30769 to 3.24630, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 4.1057 - policy_loss: 3.2463 - value_loss: 0.6927 - policy_categorical_accuracy: 0.2591 - value_mse: 0.1181\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 4.19396 | Policy loss 3.33709 | Value loss 0.69276 | Policy acc 0.25970 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 13\n",
            "157/157 [==============================] - ETA: 0s - loss: 4.0250 - policy_loss: 3.1706 - value_loss: 0.6928 - policy_categorical_accuracy: 0.2740 - value_mse: 0.1193\n",
            "Epoch 00001: policy_loss improved from 3.24630 to 3.17064, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 229ms/step - loss: 4.0250 - policy_loss: 3.1706 - value_loss: 0.6928 - policy_categorical_accuracy: 0.2740 - value_mse: 0.1193\n",
            "epoch 14\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.9599 - policy_loss: 3.1102 - value_loss: 0.6930 - policy_categorical_accuracy: 0.2872 - value_mse: 0.1180\n",
            "Epoch 00001: policy_loss improved from 3.17064 to 3.11015, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.9599 - policy_loss: 3.1102 - value_loss: 0.6930 - policy_categorical_accuracy: 0.2872 - value_mse: 0.1180\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 4.09399 | Policy loss 3.24666 | Value loss 0.69280 | Policy acc 0.27120 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 15\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.9406 - policy_loss: 3.0952 - value_loss: 0.6930 - policy_categorical_accuracy: 0.2845 - value_mse: 0.1194\n",
            "Epoch 00001: policy_loss improved from 3.11015 to 3.09524, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.9406 - policy_loss: 3.0952 - value_loss: 0.6930 - policy_categorical_accuracy: 0.2845 - value_mse: 0.1194\n",
            "epoch 16\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.8932 - policy_loss: 3.0508 - value_loss: 0.6930 - policy_categorical_accuracy: 0.2989 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss improved from 3.09524 to 3.05081, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.8932 - policy_loss: 3.0508 - value_loss: 0.6930 - policy_categorical_accuracy: 0.2989 - value_mse: 0.1182\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.93389 | Policy loss 3.09344 | Value loss 0.69281 | Policy acc 0.28710 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 17\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.8494 - policy_loss: 3.0108 - value_loss: 0.6928 - policy_categorical_accuracy: 0.2992 - value_mse: 0.1195\n",
            "Epoch 00001: policy_loss improved from 3.05081 to 3.01078, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.8494 - policy_loss: 3.0108 - value_loss: 0.6928 - policy_categorical_accuracy: 0.2992 - value_mse: 0.1195\n",
            "epoch 18\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.8316 - policy_loss: 2.9972 - value_loss: 0.6926 - policy_categorical_accuracy: 0.2999 - value_mse: 0.1199\n",
            "Epoch 00001: policy_loss improved from 3.01078 to 2.99719, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 231ms/step - loss: 3.8316 - policy_loss: 2.9972 - value_loss: 0.6926 - policy_categorical_accuracy: 0.2999 - value_mse: 0.1199\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.86531 | Policy loss 3.03257 | Value loss 0.69276 | Policy acc 0.29890 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 19\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.8214 - policy_loss: 2.9902 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3059 - value_mse: 0.1174\n",
            "Epoch 00001: policy_loss improved from 2.99719 to 2.99019, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.8214 - policy_loss: 2.9902 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3059 - value_mse: 0.1174\n",
            "epoch 20\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.7744 - policy_loss: 2.9462 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3037 - value_mse: 0.1210\n",
            "Epoch 00001: policy_loss improved from 2.99019 to 2.94624, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 229ms/step - loss: 3.7744 - policy_loss: 2.9462 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3037 - value_mse: 0.1210\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.83744 | Policy loss 3.01105 | Value loss 0.69277 | Policy acc 0.30560 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 21\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.7514 - policy_loss: 2.9265 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3120 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss improved from 2.94624 to 2.92653, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.7514 - policy_loss: 2.9265 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3120 - value_mse: 0.1181\n",
            "epoch 22\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.7030 - policy_loss: 2.8813 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3158 - value_mse: 0.1190\n",
            "Epoch 00001: policy_loss improved from 2.92653 to 2.88131, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.7030 - policy_loss: 2.8813 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3158 - value_mse: 0.1190\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.77197 | Policy loss 2.95171 | Value loss 0.69276 | Policy acc 0.31360 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 23\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.6949 - policy_loss: 2.8760 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3221 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss improved from 2.88131 to 2.87598, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.6949 - policy_loss: 2.8760 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3221 - value_mse: 0.1177\n",
            "epoch 24\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.7060 - policy_loss: 2.8892 - value_loss: 0.6932 - policy_categorical_accuracy: 0.3132 - value_mse: 0.1183\n",
            "Epoch 00001: policy_loss did not improve from 2.87598\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.7060 - policy_loss: 2.8892 - value_loss: 0.6932 - policy_categorical_accuracy: 0.3132 - value_mse: 0.1183\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.71589 | Policy loss 2.90076 | Value loss 0.69283 | Policy acc 0.31510 | Value MSE 0.11724 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 25\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.6654 - policy_loss: 2.8507 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3213 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss improved from 2.87598 to 2.85068, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.6654 - policy_loss: 2.8507 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3213 - value_mse: 0.1184\n",
            "epoch 26\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.6453 - policy_loss: 2.8318 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3275 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss improved from 2.85068 to 2.83177, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.6453 - policy_loss: 2.8318 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3275 - value_mse: 0.1184\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.72963 | Policy loss 2.91732 | Value loss 0.69277 | Policy acc 0.31490 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 27\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.6348 - policy_loss: 2.8235 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3252 - value_mse: 0.1183\n",
            "Epoch 00001: policy_loss improved from 2.83177 to 2.82345, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.6348 - policy_loss: 2.8235 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3252 - value_mse: 0.1183\n",
            "epoch 28\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.6491 - policy_loss: 2.8402 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3252 - value_mse: 0.1183\n",
            "Epoch 00001: policy_loss did not improve from 2.82345\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.6491 - policy_loss: 2.8402 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3252 - value_mse: 0.1183\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.65080 | Policy loss 2.84326 | Value loss 0.69278 | Policy acc 0.32290 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 29\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.6322 - policy_loss: 2.8253 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3300 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss did not improve from 2.82345\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.6322 - policy_loss: 2.8253 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3300 - value_mse: 0.1181\n",
            "epoch 30\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.5826 - policy_loss: 2.7777 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3363 - value_mse: 0.1193\n",
            "Epoch 00001: policy_loss improved from 2.82345 to 2.77769, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.5826 - policy_loss: 2.7777 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3363 - value_mse: 0.1193\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.63791 | Policy loss 2.83365 | Value loss 0.69276 | Policy acc 0.32650 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 31\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.5744 - policy_loss: 2.7703 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3324 - value_mse: 0.1172\n",
            "Epoch 00001: policy_loss improved from 2.77769 to 2.77032, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.5744 - policy_loss: 2.7703 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3324 - value_mse: 0.1172\n",
            "epoch 32\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.5451 - policy_loss: 2.7409 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3368 - value_mse: 0.1195\n",
            "Epoch 00001: policy_loss improved from 2.77032 to 2.74089, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.5451 - policy_loss: 2.7409 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3368 - value_mse: 0.1195\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.63256 | Policy loss 2.82961 | Value loss 0.69287 | Policy acc 0.32540 | Value MSE 0.11726 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 33\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.5280 - policy_loss: 2.7253 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3395 - value_mse: 0.1159\n",
            "Epoch 00001: policy_loss improved from 2.74089 to 2.72530, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.5280 - policy_loss: 2.7253 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3395 - value_mse: 0.1159\n",
            "epoch 34\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.5319 - policy_loss: 2.7303 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3452 - value_mse: 0.1167\n",
            "Epoch 00001: policy_loss did not improve from 2.72530\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.5319 - policy_loss: 2.7303 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3452 - value_mse: 0.1167\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.63910 | Policy loss 2.83870 | Value loss 0.69289 | Policy acc 0.32240 | Value MSE 0.11727 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 35\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.5038 - policy_loss: 2.7041 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3436 - value_mse: 0.1197\n",
            "Epoch 00001: policy_loss improved from 2.72530 to 2.70405, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.5038 - policy_loss: 2.7041 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3436 - value_mse: 0.1197\n",
            "epoch 36\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.5378 - policy_loss: 2.7387 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3336 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 2.70405\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.5378 - policy_loss: 2.7387 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3336 - value_mse: 0.1182\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.60620 | Policy loss 2.80707 | Value loss 0.69277 | Policy acc 0.32440 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 37\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.5515 - policy_loss: 2.7530 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3319 - value_mse: 0.1170\n",
            "Epoch 00001: policy_loss did not improve from 2.70405\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.5515 - policy_loss: 2.7530 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3319 - value_mse: 0.1170\n",
            "epoch 38\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.5077 - policy_loss: 2.7100 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3406 - value_mse: 0.1198\n",
            "Epoch 00001: policy_loss did not improve from 2.70405\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.5077 - policy_loss: 2.7100 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3406 - value_mse: 0.1198\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.52212 | Policy loss 2.72424 | Value loss 0.69280 | Policy acc 0.34190 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 39\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.4836 - policy_loss: 2.6866 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3492 - value_mse: 0.1174\n",
            "Epoch 00001: policy_loss improved from 2.70405 to 2.68662, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 231ms/step - loss: 3.4836 - policy_loss: 2.6866 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3492 - value_mse: 0.1174\n",
            "epoch 40\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.4795 - policy_loss: 2.6837 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3458 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss improved from 2.68662 to 2.68375, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.4795 - policy_loss: 2.6837 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3458 - value_mse: 0.1177\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.53604 | Policy loss 2.74092 | Value loss 0.69276 | Policy acc 0.33790 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 41\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.5179 - policy_loss: 2.7230 - value_loss: 0.6932 - policy_categorical_accuracy: 0.3401 - value_mse: 0.1172\n",
            "Epoch 00001: policy_loss did not improve from 2.68375\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.5179 - policy_loss: 2.7230 - value_loss: 0.6932 - policy_categorical_accuracy: 0.3401 - value_mse: 0.1172\n",
            "epoch 42\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.4501 - policy_loss: 2.6565 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3548 - value_mse: 0.1178\n",
            "Epoch 00001: policy_loss improved from 2.68375 to 2.65647, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.4501 - policy_loss: 2.6565 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3548 - value_mse: 0.1178\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.50964 | Policy loss 2.71620 | Value loss 0.69277 | Policy acc 0.34150 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 43\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.5197 - policy_loss: 2.7220 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3431 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 2.65647\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.5197 - policy_loss: 2.7220 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3431 - value_mse: 0.1177\n",
            "epoch 44\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.4317 - policy_loss: 2.6350 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3561 - value_mse: 0.1165\n",
            "Epoch 00001: policy_loss improved from 2.65647 to 2.63495, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.4317 - policy_loss: 2.6350 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3561 - value_mse: 0.1165\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.52285 | Policy loss 2.72747 | Value loss 0.69277 | Policy acc 0.35110 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 45\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.4631 - policy_loss: 2.6681 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3453 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 2.63495\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.4631 - policy_loss: 2.6681 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3453 - value_mse: 0.1177\n",
            "epoch 46\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.4363 - policy_loss: 2.6426 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3575 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss did not improve from 2.63495\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.4363 - policy_loss: 2.6426 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3575 - value_mse: 0.1181\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.48809 | Policy loss 2.69529 | Value loss 0.69286 | Policy acc 0.34550 | Value MSE 0.11726 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 47\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.4216 - policy_loss: 2.6290 - value_loss: 0.6932 - policy_categorical_accuracy: 0.3531 - value_mse: 0.1170\n",
            "Epoch 00001: policy_loss improved from 2.63495 to 2.62898, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.4216 - policy_loss: 2.6290 - value_loss: 0.6932 - policy_categorical_accuracy: 0.3531 - value_mse: 0.1170\n",
            "epoch 48\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.4205 - policy_loss: 2.6287 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3576 - value_mse: 0.1170\n",
            "Epoch 00001: policy_loss improved from 2.62898 to 2.62869, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.4205 - policy_loss: 2.6287 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3576 - value_mse: 0.1170\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.47804 | Policy loss 2.68655 | Value loss 0.69286 | Policy acc 0.35000 | Value MSE 0.11726 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 49\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.4175 - policy_loss: 2.6252 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3514 - value_mse: 0.1189\n",
            "Epoch 00001: policy_loss improved from 2.62869 to 2.62518, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.4175 - policy_loss: 2.6252 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3514 - value_mse: 0.1189\n",
            "epoch 50\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.4076 - policy_loss: 2.6162 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3566 - value_mse: 0.1172\n",
            "Epoch 00001: policy_loss improved from 2.62518 to 2.61624, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.4076 - policy_loss: 2.6162 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3566 - value_mse: 0.1172\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.41398 | Policy loss 2.62313 | Value loss 0.69281 | Policy acc 0.35660 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 51\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.4025 - policy_loss: 2.6116 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3540 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss improved from 2.61624 to 2.61165, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.4025 - policy_loss: 2.6116 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3540 - value_mse: 0.1185\n",
            "epoch 52\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.4052 - policy_loss: 2.6145 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3605 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 2.61165\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.4052 - policy_loss: 2.6145 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3605 - value_mse: 0.1182\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.40041 | Policy loss 2.61030 | Value loss 0.69278 | Policy acc 0.35960 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 53\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3673 - policy_loss: 2.5772 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3591 - value_mse: 0.1172\n",
            "Epoch 00001: policy_loss improved from 2.61165 to 2.57719, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.3673 - policy_loss: 2.5772 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3591 - value_mse: 0.1172\n",
            "epoch 54\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.4066 - policy_loss: 2.6156 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3586 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 2.57719\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.4066 - policy_loss: 2.6156 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3586 - value_mse: 0.1182\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.42521 | Policy loss 2.63457 | Value loss 0.69285 | Policy acc 0.34960 | Value MSE 0.11725 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 55\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3955 - policy_loss: 2.6055 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3503 - value_mse: 0.1189\n",
            "Epoch 00001: policy_loss did not improve from 2.57719\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.3955 - policy_loss: 2.6055 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3503 - value_mse: 0.1189\n",
            "epoch 56\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3747 - policy_loss: 2.5855 - value_loss: 0.6925 - policy_categorical_accuracy: 0.3620 - value_mse: 0.1176\n",
            "Epoch 00001: policy_loss did not improve from 2.57719\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.3747 - policy_loss: 2.5855 - value_loss: 0.6925 - policy_categorical_accuracy: 0.3620 - value_mse: 0.1176\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.41319 | Policy loss 2.62397 | Value loss 0.69276 | Policy acc 0.35490 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 57\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3938 - policy_loss: 2.6032 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3555 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss did not improve from 2.57719\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.3938 - policy_loss: 2.6032 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3555 - value_mse: 0.1185\n",
            "epoch 58\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3730 - policy_loss: 2.5828 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3594 - value_mse: 0.1175\n",
            "Epoch 00001: policy_loss did not improve from 2.57719\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.3730 - policy_loss: 2.5828 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3594 - value_mse: 0.1175\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.38096 | Policy loss 2.59120 | Value loss 0.69276 | Policy acc 0.35330 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 59\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3439 - policy_loss: 2.5542 - value_loss: 0.6926 - policy_categorical_accuracy: 0.3649 - value_mse: 0.1179\n",
            "Epoch 00001: policy_loss improved from 2.57719 to 2.55417, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.3439 - policy_loss: 2.5542 - value_loss: 0.6926 - policy_categorical_accuracy: 0.3649 - value_mse: 0.1179\n",
            "epoch 60\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3688 - policy_loss: 2.5794 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3609 - value_mse: 0.1183\n",
            "Epoch 00001: policy_loss did not improve from 2.55417\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.3688 - policy_loss: 2.5794 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3609 - value_mse: 0.1183\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.38306 | Policy loss 2.59271 | Value loss 0.69276 | Policy acc 0.35990 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 61\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3658 - policy_loss: 2.5744 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3668 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 2.55417\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.3658 - policy_loss: 2.5744 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3668 - value_mse: 0.1182\n",
            "epoch 62\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3335 - policy_loss: 2.5427 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3708 - value_mse: 0.1195\n",
            "Epoch 00001: policy_loss improved from 2.55417 to 2.54272, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 231ms/step - loss: 3.3335 - policy_loss: 2.5427 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3708 - value_mse: 0.1195\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.33893 | Policy loss 2.54909 | Value loss 0.69276 | Policy acc 0.36300 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 63\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3315 - policy_loss: 2.5409 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3649 - value_mse: 0.1187\n",
            "Epoch 00001: policy_loss improved from 2.54272 to 2.54092, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.3315 - policy_loss: 2.5409 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3649 - value_mse: 0.1187\n",
            "epoch 64\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3646 - policy_loss: 2.5716 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3637 - value_mse: 0.1201\n",
            "Epoch 00001: policy_loss did not improve from 2.54092\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.3646 - policy_loss: 2.5716 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3637 - value_mse: 0.1201\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.35929 | Policy loss 2.56761 | Value loss 0.69275 | Policy acc 0.36510 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 65\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3240 - policy_loss: 2.5330 - value_loss: 0.6933 - policy_categorical_accuracy: 0.3649 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss improved from 2.54092 to 2.53297, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 231ms/step - loss: 3.3240 - policy_loss: 2.5330 - value_loss: 0.6933 - policy_categorical_accuracy: 0.3649 - value_mse: 0.1184\n",
            "epoch 66\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3297 - policy_loss: 2.5400 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3643 - value_mse: 0.1170\n",
            "Epoch 00001: policy_loss did not improve from 2.53297\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.3297 - policy_loss: 2.5400 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3643 - value_mse: 0.1170\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.34752 | Policy loss 2.55823 | Value loss 0.69278 | Policy acc 0.36210 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 67\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3066 - policy_loss: 2.5172 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3729 - value_mse: 0.1178\n",
            "Epoch 00001: policy_loss improved from 2.53297 to 2.51720, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.3066 - policy_loss: 2.5172 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3729 - value_mse: 0.1178\n",
            "epoch 68\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3420 - policy_loss: 2.5523 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3648 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 2.51720\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.3420 - policy_loss: 2.5523 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3648 - value_mse: 0.1182\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.35969 | Policy loss 2.57005 | Value loss 0.69311 | Policy acc 0.36160 | Value MSE 0.11737 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 69\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3296 - policy_loss: 2.5404 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3647 - value_mse: 0.1180\n",
            "Epoch 00001: policy_loss did not improve from 2.51720\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.3296 - policy_loss: 2.5404 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3647 - value_mse: 0.1180\n",
            "epoch 70\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3539 - policy_loss: 2.5549 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3651 - value_mse: 0.1176\n",
            "Epoch 00001: policy_loss did not improve from 2.51720\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.3539 - policy_loss: 2.5549 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3651 - value_mse: 0.1176\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.34634 | Policy loss 2.54874 | Value loss 0.69277 | Policy acc 0.36960 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 71\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3053 - policy_loss: 2.5098 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3731 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss improved from 2.51720 to 2.50985, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 231ms/step - loss: 3.3053 - policy_loss: 2.5098 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3731 - value_mse: 0.1181\n",
            "epoch 72\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3168 - policy_loss: 2.5233 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3719 - value_mse: 0.1193\n",
            "Epoch 00001: policy_loss did not improve from 2.50985\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.3168 - policy_loss: 2.5233 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3719 - value_mse: 0.1193\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.31058 | Policy loss 2.51818 | Value loss 0.69276 | Policy acc 0.37160 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 73\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2766 - policy_loss: 2.4848 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3760 - value_mse: 0.1195\n",
            "Epoch 00001: policy_loss improved from 2.50985 to 2.48483, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 231ms/step - loss: 3.2766 - policy_loss: 2.4848 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3760 - value_mse: 0.1195\n",
            "epoch 74\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2440 - policy_loss: 2.4534 - value_loss: 0.6932 - policy_categorical_accuracy: 0.3845 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss improved from 2.48483 to 2.45342, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.2440 - policy_loss: 2.4534 - value_loss: 0.6932 - policy_categorical_accuracy: 0.3845 - value_mse: 0.1185\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.33809 | Policy loss 2.54827 | Value loss 0.69281 | Policy acc 0.36620 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 75\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2982 - policy_loss: 2.5082 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3722 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 2.45342\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.2982 - policy_loss: 2.5082 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3722 - value_mse: 0.1177\n",
            "epoch 76\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2777 - policy_loss: 2.4876 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3775 - value_mse: 0.1201\n",
            "Epoch 00001: policy_loss did not improve from 2.45342\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.2777 - policy_loss: 2.4876 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3775 - value_mse: 0.1201\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.30541 | Policy loss 2.51606 | Value loss 0.69276 | Policy acc 0.37420 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 77\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2991 - policy_loss: 2.5084 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3703 - value_mse: 0.1173\n",
            "Epoch 00001: policy_loss did not improve from 2.45342\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.2991 - policy_loss: 2.5084 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3703 - value_mse: 0.1173\n",
            "epoch 78\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2691 - policy_loss: 2.4792 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3744 - value_mse: 0.1188\n",
            "Epoch 00001: policy_loss did not improve from 2.45342\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.2691 - policy_loss: 2.4792 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3744 - value_mse: 0.1188\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.29847 | Policy loss 2.50929 | Value loss 0.69276 | Policy acc 0.37020 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 79\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.3173 - policy_loss: 2.5280 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3694 - value_mse: 0.1178\n",
            "Epoch 00001: policy_loss did not improve from 2.45342\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.3173 - policy_loss: 2.5280 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3694 - value_mse: 0.1178\n",
            "epoch 80\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2704 - policy_loss: 2.4811 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3801 - value_mse: 0.1190\n",
            "Epoch 00001: policy_loss did not improve from 2.45342\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.2704 - policy_loss: 2.4811 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3801 - value_mse: 0.1190\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.31509 | Policy loss 2.52602 | Value loss 0.69282 | Policy acc 0.37550 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 81\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2811 - policy_loss: 2.4911 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3719 - value_mse: 0.1173\n",
            "Epoch 00001: policy_loss did not improve from 2.45342\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.2811 - policy_loss: 2.4911 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3719 - value_mse: 0.1173\n",
            "epoch 82\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2932 - policy_loss: 2.5039 - value_loss: 0.6926 - policy_categorical_accuracy: 0.3758 - value_mse: 0.1187\n",
            "Epoch 00001: policy_loss did not improve from 2.45342\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.2932 - policy_loss: 2.5039 - value_loss: 0.6926 - policy_categorical_accuracy: 0.3758 - value_mse: 0.1187\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.31092 | Policy loss 2.52144 | Value loss 0.69276 | Policy acc 0.36300 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 83\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2709 - policy_loss: 2.4815 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3709 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss did not improve from 2.45342\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.2709 - policy_loss: 2.4815 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3709 - value_mse: 0.1185\n",
            "epoch 84\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2918 - policy_loss: 2.5031 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3760 - value_mse: 0.1198\n",
            "Epoch 00001: policy_loss did not improve from 2.45342\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.2918 - policy_loss: 2.5031 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3760 - value_mse: 0.1198\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.26904 | Policy loss 2.48012 | Value loss 0.69276 | Policy acc 0.38200 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 85\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2659 - policy_loss: 2.4773 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3772 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss did not improve from 2.45342\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.2659 - policy_loss: 2.4773 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3772 - value_mse: 0.1191\n",
            "epoch 86\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2497 - policy_loss: 2.4618 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3805 - value_mse: 0.1164\n",
            "Epoch 00001: policy_loss did not improve from 2.45342\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.2497 - policy_loss: 2.4618 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3805 - value_mse: 0.1164\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.25754 | Policy loss 2.46935 | Value loss 0.69276 | Policy acc 0.37650 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 87\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2485 - policy_loss: 2.4576 - value_loss: 0.6933 - policy_categorical_accuracy: 0.3782 - value_mse: 0.1160\n",
            "Epoch 00001: policy_loss did not improve from 2.45342\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.2485 - policy_loss: 2.4576 - value_loss: 0.6933 - policy_categorical_accuracy: 0.3782 - value_mse: 0.1160\n",
            "epoch 88\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2289 - policy_loss: 2.4390 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3822 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss improved from 2.45342 to 2.43897, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.2289 - policy_loss: 2.4390 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3822 - value_mse: 0.1184\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.29666 | Policy loss 2.50758 | Value loss 0.69280 | Policy acc 0.36480 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 89\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2653 - policy_loss: 2.4759 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3831 - value_mse: 0.1168\n",
            "Epoch 00001: policy_loss did not improve from 2.43897\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.2653 - policy_loss: 2.4759 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3831 - value_mse: 0.1168\n",
            "epoch 90\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2308 - policy_loss: 2.4428 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3798 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 2.43897\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.2308 - policy_loss: 2.4428 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3798 - value_mse: 0.1177\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.28394 | Policy loss 2.49579 | Value loss 0.69280 | Policy acc 0.37160 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 91\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2612 - policy_loss: 2.4735 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3737 - value_mse: 0.1174\n",
            "Epoch 00001: policy_loss did not improve from 2.43897\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.2612 - policy_loss: 2.4735 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3737 - value_mse: 0.1174\n",
            "epoch 92\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2300 - policy_loss: 2.4427 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3795 - value_mse: 0.1195\n",
            "Epoch 00001: policy_loss did not improve from 2.43897\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.2300 - policy_loss: 2.4427 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3795 - value_mse: 0.1195\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.27598 | Policy loss 2.48907 | Value loss 0.69276 | Policy acc 0.37300 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 93\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2341 - policy_loss: 2.4473 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3819 - value_mse: 0.1202\n",
            "Epoch 00001: policy_loss did not improve from 2.43897\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.2341 - policy_loss: 2.4473 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3819 - value_mse: 0.1202\n",
            "epoch 94\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2200 - policy_loss: 2.4331 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3783 - value_mse: 0.1203\n",
            "Epoch 00001: policy_loss improved from 2.43897 to 2.43310, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 231ms/step - loss: 3.2200 - policy_loss: 2.4331 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3783 - value_mse: 0.1203\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.29214 | Policy loss 2.50508 | Value loss 0.69276 | Policy acc 0.37790 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 95\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1975 - policy_loss: 2.4102 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3901 - value_mse: 0.1180\n",
            "Epoch 00001: policy_loss improved from 2.43310 to 2.41016, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.1975 - policy_loss: 2.4102 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3901 - value_mse: 0.1180\n",
            "epoch 96\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2093 - policy_loss: 2.4225 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3856 - value_mse: 0.1204\n",
            "Epoch 00001: policy_loss did not improve from 2.41016\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.2093 - policy_loss: 2.4225 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3856 - value_mse: 0.1204\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.23831 | Policy loss 2.45158 | Value loss 0.69276 | Policy acc 0.37780 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 97\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2168 - policy_loss: 2.4302 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3885 - value_mse: 0.1186\n",
            "Epoch 00001: policy_loss did not improve from 2.41016\n",
            "157/157 [==============================] - 35s 220ms/step - loss: 3.2168 - policy_loss: 2.4302 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3885 - value_mse: 0.1186\n",
            "epoch 98\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2295 - policy_loss: 2.4427 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3776 - value_mse: 0.1187\n",
            "Epoch 00001: policy_loss did not improve from 2.41016\n",
            "157/157 [==============================] - 35s 220ms/step - loss: 3.2295 - policy_loss: 2.4427 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3776 - value_mse: 0.1187\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.24262 | Policy loss 2.45603 | Value loss 0.69276 | Policy acc 0.38060 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 99\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2369 - policy_loss: 2.4500 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3820 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 2.41016\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.2369 - policy_loss: 2.4500 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3820 - value_mse: 0.1177\n",
            "epoch 100\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2228 - policy_loss: 2.4353 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3805 - value_mse: 0.1165\n",
            "Epoch 00001: policy_loss did not improve from 2.41016\n",
            "157/157 [==============================] - 35s 220ms/step - loss: 3.2228 - policy_loss: 2.4353 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3805 - value_mse: 0.1165\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.22829 | Policy loss 2.44101 | Value loss 0.69276 | Policy acc 0.38380 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 101\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2452 - policy_loss: 2.4585 - value_loss: 0.6926 - policy_categorical_accuracy: 0.3783 - value_mse: 0.1179\n",
            "Epoch 00001: policy_loss did not improve from 2.41016\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.2452 - policy_loss: 2.4585 - value_loss: 0.6926 - policy_categorical_accuracy: 0.3783 - value_mse: 0.1179\n",
            "epoch 102\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1787 - policy_loss: 2.3909 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3917 - value_mse: 0.1199\n",
            "Epoch 00001: policy_loss improved from 2.41016 to 2.39087, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 229ms/step - loss: 3.1787 - policy_loss: 2.3909 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3917 - value_mse: 0.1199\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.22965 | Policy loss 2.44181 | Value loss 0.69276 | Policy acc 0.38290 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 103\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2159 - policy_loss: 2.4288 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3797 - value_mse: 0.1172\n",
            "Epoch 00001: policy_loss did not improve from 2.39087\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.2159 - policy_loss: 2.4288 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3797 - value_mse: 0.1172\n",
            "epoch 104\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2102 - policy_loss: 2.4240 - value_loss: 0.6926 - policy_categorical_accuracy: 0.3858 - value_mse: 0.1190\n",
            "Epoch 00001: policy_loss did not improve from 2.39087\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.2102 - policy_loss: 2.4240 - value_loss: 0.6926 - policy_categorical_accuracy: 0.3858 - value_mse: 0.1190\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.22175 | Policy loss 2.43546 | Value loss 0.69276 | Policy acc 0.38010 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 105\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2094 - policy_loss: 2.4236 - value_loss: 0.6925 - policy_categorical_accuracy: 0.3847 - value_mse: 0.1190\n",
            "Epoch 00001: policy_loss did not improve from 2.39087\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.2094 - policy_loss: 2.4236 - value_loss: 0.6925 - policy_categorical_accuracy: 0.3847 - value_mse: 0.1190\n",
            "epoch 106\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2506 - policy_loss: 2.4633 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3699 - value_mse: 0.1171\n",
            "Epoch 00001: policy_loss did not improve from 2.39087\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.2506 - policy_loss: 2.4633 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3699 - value_mse: 0.1171\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.21161 | Policy loss 2.42498 | Value loss 0.69276 | Policy acc 0.38270 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 107\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1804 - policy_loss: 2.3943 - value_loss: 0.6926 - policy_categorical_accuracy: 0.3908 - value_mse: 0.1194\n",
            "Epoch 00001: policy_loss did not improve from 2.39087\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.1804 - policy_loss: 2.3943 - value_loss: 0.6926 - policy_categorical_accuracy: 0.3908 - value_mse: 0.1194\n",
            "epoch 108\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1805 - policy_loss: 2.3942 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3938 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss did not improve from 2.39087\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.1805 - policy_loss: 2.3942 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3938 - value_mse: 0.1191\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.20868 | Policy loss 2.42277 | Value loss 0.69276 | Policy acc 0.37980 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 109\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1913 - policy_loss: 2.4046 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3872 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss did not improve from 2.39087\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1913 - policy_loss: 2.4046 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3872 - value_mse: 0.1184\n",
            "epoch 110\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2090 - policy_loss: 2.4227 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3820 - value_mse: 0.1194\n",
            "Epoch 00001: policy_loss did not improve from 2.39087\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.2090 - policy_loss: 2.4227 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3820 - value_mse: 0.1194\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.21553 | Policy loss 2.42939 | Value loss 0.69277 | Policy acc 0.38330 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 111\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1938 - policy_loss: 2.4075 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3866 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss did not improve from 2.39087\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1938 - policy_loss: 2.4075 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3866 - value_mse: 0.1181\n",
            "epoch 112\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1675 - policy_loss: 2.3818 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3931 - value_mse: 0.1168\n",
            "Epoch 00001: policy_loss improved from 2.39087 to 2.38180, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.1675 - policy_loss: 2.3818 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3931 - value_mse: 0.1168\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.20534 | Policy loss 2.41996 | Value loss 0.69276 | Policy acc 0.38420 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 113\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1739 - policy_loss: 2.3879 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3812 - value_mse: 0.1178\n",
            "Epoch 00001: policy_loss did not improve from 2.38180\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.1739 - policy_loss: 2.3879 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3812 - value_mse: 0.1178\n",
            "epoch 114\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1396 - policy_loss: 2.3541 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3967 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss improved from 2.38180 to 2.35407, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 3.1396 - policy_loss: 2.3541 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3967 - value_mse: 0.1191\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.20957 | Policy loss 2.42443 | Value loss 0.69278 | Policy acc 0.37800 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 115\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1815 - policy_loss: 2.3951 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3886 - value_mse: 0.1195\n",
            "Epoch 00001: policy_loss did not improve from 2.35407\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.1815 - policy_loss: 2.3951 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3886 - value_mse: 0.1195\n",
            "epoch 116\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.2073 - policy_loss: 2.4202 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3860 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss did not improve from 2.35407\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.2073 - policy_loss: 2.4202 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3860 - value_mse: 0.1184\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.20472 | Policy loss 2.41691 | Value loss 0.69281 | Policy acc 0.38520 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 117\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1655 - policy_loss: 2.3790 - value_loss: 0.6926 - policy_categorical_accuracy: 0.3877 - value_mse: 0.1173\n",
            "Epoch 00001: policy_loss did not improve from 2.35407\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1655 - policy_loss: 2.3790 - value_loss: 0.6926 - policy_categorical_accuracy: 0.3877 - value_mse: 0.1173\n",
            "epoch 118\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1431 - policy_loss: 2.3574 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3939 - value_mse: 0.1166\n",
            "Epoch 00001: policy_loss did not improve from 2.35407\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.1431 - policy_loss: 2.3574 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3939 - value_mse: 0.1166\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.17918 | Policy loss 2.39398 | Value loss 0.69276 | Policy acc 0.38730 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 119\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1674 - policy_loss: 2.3818 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3878 - value_mse: 0.1176\n",
            "Epoch 00001: policy_loss did not improve from 2.35407\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.1674 - policy_loss: 2.3818 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3878 - value_mse: 0.1176\n",
            "epoch 120\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1785 - policy_loss: 2.3919 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3902 - value_mse: 0.1189\n",
            "Epoch 00001: policy_loss did not improve from 2.35407\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.1785 - policy_loss: 2.3919 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3902 - value_mse: 0.1189\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.17756 | Policy loss 2.39142 | Value loss 0.69278 | Policy acc 0.38660 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 121\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1421 - policy_loss: 2.3559 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3931 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss did not improve from 2.35407\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.1421 - policy_loss: 2.3559 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3931 - value_mse: 0.1184\n",
            "epoch 122\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1556 - policy_loss: 2.3700 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3897 - value_mse: 0.1168\n",
            "Epoch 00001: policy_loss did not improve from 2.35407\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.1556 - policy_loss: 2.3700 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3897 - value_mse: 0.1168\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.16816 | Policy loss 2.38292 | Value loss 0.69276 | Policy acc 0.39080 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 123\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1798 - policy_loss: 2.3943 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3858 - value_mse: 0.1170\n",
            "Epoch 00001: policy_loss did not improve from 2.35407\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.1798 - policy_loss: 2.3943 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3858 - value_mse: 0.1170\n",
            "epoch 124\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1535 - policy_loss: 2.3679 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4021 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 2.35407\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.1535 - policy_loss: 2.3679 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4021 - value_mse: 0.1182\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.21239 | Policy loss 2.42674 | Value loss 0.69280 | Policy acc 0.38610 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 125\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1392 - policy_loss: 2.3538 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3958 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss improved from 2.35407 to 2.35383, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 229ms/step - loss: 3.1392 - policy_loss: 2.3538 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3958 - value_mse: 0.1184\n",
            "epoch 126\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1671 - policy_loss: 2.3803 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3865 - value_mse: 0.1163\n",
            "Epoch 00001: policy_loss did not improve from 2.35383\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.1671 - policy_loss: 2.3803 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3865 - value_mse: 0.1163\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.18371 | Policy loss 2.39552 | Value loss 0.69276 | Policy acc 0.39520 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 127\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1871 - policy_loss: 2.3996 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3869 - value_mse: 0.1189\n",
            "Epoch 00001: policy_loss did not improve from 2.35383\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1871 - policy_loss: 2.3996 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3869 - value_mse: 0.1189\n",
            "epoch 128\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1689 - policy_loss: 2.3817 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3887 - value_mse: 0.1173\n",
            "Epoch 00001: policy_loss did not improve from 2.35383\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.1689 - policy_loss: 2.3817 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3887 - value_mse: 0.1173\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.17841 | Policy loss 2.39141 | Value loss 0.69277 | Policy acc 0.38920 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 129\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1566 - policy_loss: 2.3700 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3960 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 2.35383\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1566 - policy_loss: 2.3700 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3960 - value_mse: 0.1182\n",
            "epoch 130\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1774 - policy_loss: 2.3910 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3909 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss did not improve from 2.35383\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.1774 - policy_loss: 2.3910 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3909 - value_mse: 0.1185\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.17081 | Policy loss 2.38508 | Value loss 0.69277 | Policy acc 0.38840 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 131\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1542 - policy_loss: 2.3685 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3928 - value_mse: 0.1188\n",
            "Epoch 00001: policy_loss did not improve from 2.35383\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1542 - policy_loss: 2.3685 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3928 - value_mse: 0.1188\n",
            "epoch 132\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1071 - policy_loss: 2.3214 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3985 - value_mse: 0.1197\n",
            "Epoch 00001: policy_loss improved from 2.35383 to 2.32135, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 3.1071 - policy_loss: 2.3214 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3985 - value_mse: 0.1197\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.19958 | Policy loss 2.41411 | Value loss 0.69281 | Policy acc 0.39250 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 133\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1428 - policy_loss: 2.3571 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3926 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss did not improve from 2.32135\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.1428 - policy_loss: 2.3571 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3926 - value_mse: 0.1181\n",
            "epoch 134\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1471 - policy_loss: 2.3612 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3965 - value_mse: 0.1190\n",
            "Epoch 00001: policy_loss did not improve from 2.32135\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.1471 - policy_loss: 2.3612 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3965 - value_mse: 0.1190\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.12915 | Policy loss 2.34382 | Value loss 0.69280 | Policy acc 0.39370 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 135\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1393 - policy_loss: 2.3538 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3928 - value_mse: 0.1186\n",
            "Epoch 00001: policy_loss did not improve from 2.32135\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.1393 - policy_loss: 2.3538 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3928 - value_mse: 0.1186\n",
            "epoch 136\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1540 - policy_loss: 2.3684 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3869 - value_mse: 0.1172\n",
            "Epoch 00001: policy_loss did not improve from 2.32135\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1540 - policy_loss: 2.3684 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3869 - value_mse: 0.1172\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.14961 | Policy loss 2.36370 | Value loss 0.69276 | Policy acc 0.39620 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 137\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1361 - policy_loss: 2.3503 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3930 - value_mse: 0.1183\n",
            "Epoch 00001: policy_loss did not improve from 2.32135\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1361 - policy_loss: 2.3503 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3930 - value_mse: 0.1183\n",
            "epoch 138\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1209 - policy_loss: 2.3359 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3993 - value_mse: 0.1194\n",
            "Epoch 00001: policy_loss did not improve from 2.32135\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1209 - policy_loss: 2.3359 - value_loss: 0.6927 - policy_categorical_accuracy: 0.3993 - value_mse: 0.1194\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.15579 | Policy loss 2.37090 | Value loss 0.69276 | Policy acc 0.39450 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 139\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1084 - policy_loss: 2.3237 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4003 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 2.32135\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1084 - policy_loss: 2.3237 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4003 - value_mse: 0.1177\n",
            "epoch 140\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1322 - policy_loss: 2.3461 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3939 - value_mse: 0.1169\n",
            "Epoch 00001: policy_loss did not improve from 2.32135\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1322 - policy_loss: 2.3461 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3939 - value_mse: 0.1169\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.14928 | Policy loss 2.36359 | Value loss 0.69276 | Policy acc 0.39600 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 141\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1543 - policy_loss: 2.3687 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3845 - value_mse: 0.1176\n",
            "Epoch 00001: policy_loss did not improve from 2.32135\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1543 - policy_loss: 2.3687 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3845 - value_mse: 0.1176\n",
            "epoch 142\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1213 - policy_loss: 2.3358 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3913 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 2.32135\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1213 - policy_loss: 2.3358 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3913 - value_mse: 0.1177\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.13068 | Policy loss 2.34565 | Value loss 0.69278 | Policy acc 0.39870 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 143\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1182 - policy_loss: 2.3330 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4021 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss did not improve from 2.32135\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1182 - policy_loss: 2.3330 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4021 - value_mse: 0.1191\n",
            "epoch 144\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1059 - policy_loss: 2.3210 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4002 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss improved from 2.32135 to 2.32102, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 3.1059 - policy_loss: 2.3210 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4002 - value_mse: 0.1182\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.13168 | Policy loss 2.34698 | Value loss 0.69284 | Policy acc 0.39780 | Value MSE 0.11724 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 145\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0917 - policy_loss: 2.3063 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4076 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss improved from 2.32102 to 2.30631, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 231ms/step - loss: 3.0917 - policy_loss: 2.3063 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4076 - value_mse: 0.1177\n",
            "epoch 146\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1233 - policy_loss: 2.3384 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3924 - value_mse: 0.1188\n",
            "Epoch 00001: policy_loss did not improve from 2.30631\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1233 - policy_loss: 2.3384 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3924 - value_mse: 0.1188\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.12455 | Policy loss 2.33991 | Value loss 0.69285 | Policy acc 0.39690 | Value MSE 0.11725 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 147\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0904 - policy_loss: 2.3060 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3998 - value_mse: 0.1170\n",
            "Epoch 00001: policy_loss improved from 2.30631 to 2.30598, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 231ms/step - loss: 3.0904 - policy_loss: 2.3060 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3998 - value_mse: 0.1170\n",
            "epoch 148\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1234 - policy_loss: 2.3389 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3990 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss did not improve from 2.30598\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1234 - policy_loss: 2.3389 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3990 - value_mse: 0.1185\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.14442 | Policy loss 2.35866 | Value loss 0.69277 | Policy acc 0.39490 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 149\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1565 - policy_loss: 2.3708 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3897 - value_mse: 0.1189\n",
            "Epoch 00001: policy_loss did not improve from 2.30598\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1565 - policy_loss: 2.3708 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3897 - value_mse: 0.1189\n",
            "epoch 150\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1186 - policy_loss: 2.3338 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3991 - value_mse: 0.1171\n",
            "Epoch 00001: policy_loss did not improve from 2.30598\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1186 - policy_loss: 2.3338 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3991 - value_mse: 0.1171\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.10649 | Policy loss 2.32146 | Value loss 0.69279 | Policy acc 0.40190 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 151\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1162 - policy_loss: 2.3310 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4026 - value_mse: 0.1183\n",
            "Epoch 00001: policy_loss did not improve from 2.30598\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1162 - policy_loss: 2.3310 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4026 - value_mse: 0.1183\n",
            "epoch 152\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0898 - policy_loss: 2.3053 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4048 - value_mse: 0.1166\n",
            "Epoch 00001: policy_loss improved from 2.30598 to 2.30531, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 231ms/step - loss: 3.0898 - policy_loss: 2.3053 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4048 - value_mse: 0.1166\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.12046 | Policy loss 2.33603 | Value loss 0.69277 | Policy acc 0.39810 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 153\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1129 - policy_loss: 2.3281 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3989 - value_mse: 0.1189\n",
            "Epoch 00001: policy_loss did not improve from 2.30531\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1129 - policy_loss: 2.3281 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3989 - value_mse: 0.1189\n",
            "epoch 154\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1188 - policy_loss: 2.3343 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3938 - value_mse: 0.1186\n",
            "Epoch 00001: policy_loss did not improve from 2.30531\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1188 - policy_loss: 2.3343 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3938 - value_mse: 0.1186\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.13759 | Policy loss 2.35365 | Value loss 0.69279 | Policy acc 0.39810 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 155\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1213 - policy_loss: 2.3374 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3993 - value_mse: 0.1192\n",
            "Epoch 00001: policy_loss did not improve from 2.30531\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1213 - policy_loss: 2.3374 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3993 - value_mse: 0.1192\n",
            "epoch 156\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1168 - policy_loss: 2.3329 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3957 - value_mse: 0.1163\n",
            "Epoch 00001: policy_loss did not improve from 2.30531\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1168 - policy_loss: 2.3329 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3957 - value_mse: 0.1163\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.10578 | Policy loss 2.32208 | Value loss 0.69278 | Policy acc 0.39590 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 157\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1146 - policy_loss: 2.3308 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4042 - value_mse: 0.1169\n",
            "Epoch 00001: policy_loss did not improve from 2.30531\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1146 - policy_loss: 2.3308 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4042 - value_mse: 0.1169\n",
            "epoch 158\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1233 - policy_loss: 2.3391 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3957 - value_mse: 0.1172\n",
            "Epoch 00001: policy_loss did not improve from 2.30531\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1233 - policy_loss: 2.3391 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3957 - value_mse: 0.1172\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.13742 | Policy loss 2.35357 | Value loss 0.69281 | Policy acc 0.39580 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 159\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1131 - policy_loss: 2.3294 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3948 - value_mse: 0.1199\n",
            "Epoch 00001: policy_loss did not improve from 2.30531\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1131 - policy_loss: 2.3294 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3948 - value_mse: 0.1199\n",
            "epoch 160\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0864 - policy_loss: 2.3027 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4034 - value_mse: 0.1190\n",
            "Epoch 00001: policy_loss improved from 2.30531 to 2.30272, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 3.0864 - policy_loss: 2.3027 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4034 - value_mse: 0.1190\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.10339 | Policy loss 2.31972 | Value loss 0.69278 | Policy acc 0.40140 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 161\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0966 - policy_loss: 2.3123 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4049 - value_mse: 0.1193\n",
            "Epoch 00001: policy_loss did not improve from 2.30272\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0966 - policy_loss: 2.3123 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4049 - value_mse: 0.1193\n",
            "epoch 162\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0938 - policy_loss: 2.3098 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3986 - value_mse: 0.1187\n",
            "Epoch 00001: policy_loss did not improve from 2.30272\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0938 - policy_loss: 2.3098 - value_loss: 0.6931 - policy_categorical_accuracy: 0.3986 - value_mse: 0.1187\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.09354 | Policy loss 2.31022 | Value loss 0.69282 | Policy acc 0.40240 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 163\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1056 - policy_loss: 2.3223 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4007 - value_mse: 0.1186\n",
            "Epoch 00001: policy_loss did not improve from 2.30272\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1056 - policy_loss: 2.3223 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4007 - value_mse: 0.1186\n",
            "epoch 164\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0890 - policy_loss: 2.3051 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4007 - value_mse: 0.1186\n",
            "Epoch 00001: policy_loss did not improve from 2.30272\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0890 - policy_loss: 2.3051 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4007 - value_mse: 0.1186\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.08856 | Policy loss 2.30469 | Value loss 0.69281 | Policy acc 0.39950 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 165\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0821 - policy_loss: 2.2986 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3972 - value_mse: 0.1186\n",
            "Epoch 00001: policy_loss improved from 2.30272 to 2.29856, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 3.0821 - policy_loss: 2.2986 - value_loss: 0.6929 - policy_categorical_accuracy: 0.3972 - value_mse: 0.1186\n",
            "epoch 166\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0869 - policy_loss: 2.3037 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3983 - value_mse: 0.1179\n",
            "Epoch 00001: policy_loss did not improve from 2.29856\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0869 - policy_loss: 2.3037 - value_loss: 0.6928 - policy_categorical_accuracy: 0.3983 - value_mse: 0.1179\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.09417 | Policy loss 2.31111 | Value loss 0.69276 | Policy acc 0.39950 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 167\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0861 - policy_loss: 2.3027 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4073 - value_mse: 0.1192\n",
            "Epoch 00001: policy_loss did not improve from 2.29856\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0861 - policy_loss: 2.3027 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4073 - value_mse: 0.1192\n",
            "epoch 168\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0589 - policy_loss: 2.2756 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4056 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss improved from 2.29856 to 2.27564, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 3.0589 - policy_loss: 2.2756 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4056 - value_mse: 0.1184\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.13619 | Policy loss 2.35320 | Value loss 0.69277 | Policy acc 0.39510 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 169\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0720 - policy_loss: 2.2888 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3978 - value_mse: 0.1187\n",
            "Epoch 00001: policy_loss did not improve from 2.27564\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0720 - policy_loss: 2.2888 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3978 - value_mse: 0.1187\n",
            "epoch 170\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0705 - policy_loss: 2.2871 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4051 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 2.27564\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0705 - policy_loss: 2.2871 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4051 - value_mse: 0.1177\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.10213 | Policy loss 2.31895 | Value loss 0.69278 | Policy acc 0.39940 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 171\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0876 - policy_loss: 2.3044 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3972 - value_mse: 0.1189\n",
            "Epoch 00001: policy_loss did not improve from 2.27564\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0876 - policy_loss: 2.3044 - value_loss: 0.6930 - policy_categorical_accuracy: 0.3972 - value_mse: 0.1189\n",
            "epoch 172\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.1020 - policy_loss: 2.3189 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4050 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss did not improve from 2.27564\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.1020 - policy_loss: 2.3189 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4050 - value_mse: 0.1181\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.11496 | Policy loss 2.33160 | Value loss 0.69277 | Policy acc 0.39910 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 173\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0666 - policy_loss: 2.2836 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4040 - value_mse: 0.1155\n",
            "Epoch 00001: policy_loss did not improve from 2.27564\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0666 - policy_loss: 2.2836 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4040 - value_mse: 0.1155\n",
            "epoch 174\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0512 - policy_loss: 2.2685 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4043 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss improved from 2.27564 to 2.26847, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 3.0512 - policy_loss: 2.2685 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4043 - value_mse: 0.1184\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.09707 | Policy loss 2.31457 | Value loss 0.69276 | Policy acc 0.40220 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 175\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0684 - policy_loss: 2.2859 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4054 - value_mse: 0.1175\n",
            "Epoch 00001: policy_loss did not improve from 2.26847\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0684 - policy_loss: 2.2859 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4054 - value_mse: 0.1175\n",
            "epoch 176\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0794 - policy_loss: 2.2970 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4056 - value_mse: 0.1166\n",
            "Epoch 00001: policy_loss did not improve from 2.26847\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0794 - policy_loss: 2.2970 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4056 - value_mse: 0.1166\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.08467 | Policy loss 2.30243 | Value loss 0.69276 | Policy acc 0.40590 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 177\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0667 - policy_loss: 2.2841 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4079 - value_mse: 0.1183\n",
            "Epoch 00001: policy_loss did not improve from 2.26847\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0667 - policy_loss: 2.2841 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4079 - value_mse: 0.1183\n",
            "epoch 178\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0692 - policy_loss: 2.2868 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4001 - value_mse: 0.1202\n",
            "Epoch 00001: policy_loss did not improve from 2.26847\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0692 - policy_loss: 2.2868 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4001 - value_mse: 0.1202\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.05788 | Policy loss 2.27565 | Value loss 0.69276 | Policy acc 0.40590 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 179\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0807 - policy_loss: 2.2944 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4040 - value_mse: 0.1189\n",
            "Epoch 00001: policy_loss did not improve from 2.26847\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0807 - policy_loss: 2.2944 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4040 - value_mse: 0.1189\n",
            "epoch 180\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0738 - policy_loss: 2.2883 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4049 - value_mse: 0.1193\n",
            "Epoch 00001: policy_loss did not improve from 2.26847\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0738 - policy_loss: 2.2883 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4049 - value_mse: 0.1193\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.09579 | Policy loss 2.31100 | Value loss 0.69276 | Policy acc 0.40500 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 181\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0719 - policy_loss: 2.2872 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4078 - value_mse: 0.1183\n",
            "Epoch 00001: policy_loss did not improve from 2.26847\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0719 - policy_loss: 2.2872 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4078 - value_mse: 0.1183\n",
            "epoch 182\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0595 - policy_loss: 2.2752 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4121 - value_mse: 0.1180\n",
            "Epoch 00001: policy_loss did not improve from 2.26847\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0595 - policy_loss: 2.2752 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4121 - value_mse: 0.1180\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.05787 | Policy loss 2.27419 | Value loss 0.69281 | Policy acc 0.40610 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 183\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0722 - policy_loss: 2.2888 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4042 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss did not improve from 2.26847\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0722 - policy_loss: 2.2888 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4042 - value_mse: 0.1184\n",
            "epoch 184\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0709 - policy_loss: 2.2874 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4050 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 2.26847\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0709 - policy_loss: 2.2874 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4050 - value_mse: 0.1182\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.07920 | Policy loss 2.29602 | Value loss 0.69276 | Policy acc 0.40020 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 185\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0773 - policy_loss: 2.2942 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4009 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss did not improve from 2.26847\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0773 - policy_loss: 2.2942 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4009 - value_mse: 0.1184\n",
            "epoch 186\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0612 - policy_loss: 2.2780 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4065 - value_mse: 0.1190\n",
            "Epoch 00001: policy_loss did not improve from 2.26847\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0612 - policy_loss: 2.2780 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4065 - value_mse: 0.1190\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.05917 | Policy loss 2.27642 | Value loss 0.69277 | Policy acc 0.40750 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 187\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0366 - policy_loss: 2.2537 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4114 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss improved from 2.26847 to 2.25373, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 231ms/step - loss: 3.0366 - policy_loss: 2.2537 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4114 - value_mse: 0.1185\n",
            "epoch 188\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0460 - policy_loss: 2.2632 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4054 - value_mse: 0.1170\n",
            "Epoch 00001: policy_loss did not improve from 2.25373\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0460 - policy_loss: 2.2632 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4054 - value_mse: 0.1170\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.05439 | Policy loss 2.27197 | Value loss 0.69279 | Policy acc 0.40680 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 189\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0576 - policy_loss: 2.2751 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4004 - value_mse: 0.1204\n",
            "Epoch 00001: policy_loss did not improve from 2.25373\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0576 - policy_loss: 2.2751 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4004 - value_mse: 0.1204\n",
            "epoch 190\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0240 - policy_loss: 2.2418 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4220 - value_mse: 0.1179\n",
            "Epoch 00001: policy_loss improved from 2.25373 to 2.24176, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 3.0240 - policy_loss: 2.2418 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4220 - value_mse: 0.1179\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.04984 | Policy loss 2.26719 | Value loss 0.69275 | Policy acc 0.41280 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 191\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0444 - policy_loss: 2.2621 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4059 - value_mse: 0.1169\n",
            "Epoch 00001: policy_loss did not improve from 2.24176\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0444 - policy_loss: 2.2621 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4059 - value_mse: 0.1169\n",
            "epoch 192\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0555 - policy_loss: 2.2732 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4049 - value_mse: 0.1176\n",
            "Epoch 00001: policy_loss did not improve from 2.24176\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0555 - policy_loss: 2.2732 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4049 - value_mse: 0.1176\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.05710 | Policy loss 2.27518 | Value loss 0.69279 | Policy acc 0.41170 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 193\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0073 - policy_loss: 2.2247 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4159 - value_mse: 0.1196\n",
            "Epoch 00001: policy_loss improved from 2.24176 to 2.22470, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 231ms/step - loss: 3.0073 - policy_loss: 2.2247 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4159 - value_mse: 0.1196\n",
            "epoch 194\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0770 - policy_loss: 2.2947 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4078 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 2.22470\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0770 - policy_loss: 2.2947 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4078 - value_mse: 0.1182\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.08369 | Policy loss 2.30150 | Value loss 0.69281 | Policy acc 0.40170 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 195\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0146 - policy_loss: 2.2323 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4166 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss did not improve from 2.22470\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0146 - policy_loss: 2.2323 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4166 - value_mse: 0.1184\n",
            "epoch 196\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0375 - policy_loss: 2.2554 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4107 - value_mse: 0.1169\n",
            "Epoch 00001: policy_loss did not improve from 2.22470\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0375 - policy_loss: 2.2554 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4107 - value_mse: 0.1169\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.05288 | Policy loss 2.27095 | Value loss 0.69277 | Policy acc 0.40860 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 197\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0409 - policy_loss: 2.2591 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4086 - value_mse: 0.1197\n",
            "Epoch 00001: policy_loss did not improve from 2.22470\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 3.0409 - policy_loss: 2.2591 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4086 - value_mse: 0.1197\n",
            "epoch 198\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0382 - policy_loss: 2.2561 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4123 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss did not improve from 2.22470\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0382 - policy_loss: 2.2561 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4123 - value_mse: 0.1181\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.04217 | Policy loss 2.26063 | Value loss 0.69281 | Policy acc 0.40850 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 199\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0331 - policy_loss: 2.2513 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4146 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 2.22470\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 3.0331 - policy_loss: 2.2513 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4146 - value_mse: 0.1177\n",
            "epoch 200\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0673 - policy_loss: 2.2854 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4027 - value_mse: 0.1190\n",
            "Epoch 00001: policy_loss did not improve from 2.22470\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0673 - policy_loss: 2.2854 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4027 - value_mse: 0.1190\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.08779 | Policy loss 2.30373 | Value loss 0.69290 | Policy acc 0.40850 | Value MSE 0.11727 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 201\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0501 - policy_loss: 2.2648 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4061 - value_mse: 0.1198\n",
            "Epoch 00001: policy_loss did not improve from 2.22470\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0501 - policy_loss: 2.2648 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4061 - value_mse: 0.1198\n",
            "epoch 202\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0578 - policy_loss: 2.2738 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4054 - value_mse: 0.1202\n",
            "Epoch 00001: policy_loss did not improve from 2.22470\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0578 - policy_loss: 2.2738 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4054 - value_mse: 0.1202\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.03693 | Policy loss 2.25342 | Value loss 0.69284 | Policy acc 0.41360 | Value MSE 0.11724 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 203\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0173 - policy_loss: 2.2338 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4120 - value_mse: 0.1178\n",
            "Epoch 00001: policy_loss did not improve from 2.22470\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0173 - policy_loss: 2.2338 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4120 - value_mse: 0.1178\n",
            "epoch 204\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0387 - policy_loss: 2.2557 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4108 - value_mse: 0.1201\n",
            "Epoch 00001: policy_loss did not improve from 2.22470\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 3.0387 - policy_loss: 2.2557 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4108 - value_mse: 0.1201\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.03236 | Policy loss 2.24968 | Value loss 0.69283 | Policy acc 0.41150 | Value MSE 0.11724 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 205\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0335 - policy_loss: 2.2509 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4122 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss did not improve from 2.22470\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0335 - policy_loss: 2.2509 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4122 - value_mse: 0.1184\n",
            "epoch 206\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0213 - policy_loss: 2.2387 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4119 - value_mse: 0.1174\n",
            "Epoch 00001: policy_loss did not improve from 2.22470\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0213 - policy_loss: 2.2387 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4119 - value_mse: 0.1174\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.07125 | Policy loss 2.28911 | Value loss 0.69282 | Policy acc 0.41280 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 207\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0055 - policy_loss: 2.2234 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4167 - value_mse: 0.1175\n",
            "Epoch 00001: policy_loss improved from 2.22470 to 2.22343, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 3.0055 - policy_loss: 2.2234 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4167 - value_mse: 0.1175\n",
            "epoch 208\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0130 - policy_loss: 2.2309 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4128 - value_mse: 0.1187\n",
            "Epoch 00001: policy_loss did not improve from 2.22343\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0130 - policy_loss: 2.2309 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4128 - value_mse: 0.1187\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.02940 | Policy loss 2.24764 | Value loss 0.69283 | Policy acc 0.41460 | Value MSE 0.11724 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 209\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0032 - policy_loss: 2.2214 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4140 - value_mse: 0.1193\n",
            "Epoch 00001: policy_loss improved from 2.22343 to 2.22137, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 3.0032 - policy_loss: 2.2214 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4140 - value_mse: 0.1193\n",
            "epoch 210\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0276 - policy_loss: 2.2459 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4110 - value_mse: 0.1158\n",
            "Epoch 00001: policy_loss did not improve from 2.22137\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0276 - policy_loss: 2.2459 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4110 - value_mse: 0.1158\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.03676 | Policy loss 2.25529 | Value loss 0.69279 | Policy acc 0.40950 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 211\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0133 - policy_loss: 2.2317 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4051 - value_mse: 0.1174\n",
            "Epoch 00001: policy_loss did not improve from 2.22137\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0133 - policy_loss: 2.2317 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4051 - value_mse: 0.1174\n",
            "epoch 212\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0078 - policy_loss: 2.2265 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4120 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 2.22137\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0078 - policy_loss: 2.2265 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4120 - value_mse: 0.1177\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.05781 | Policy loss 2.27667 | Value loss 0.69279 | Policy acc 0.40660 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 213\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0271 - policy_loss: 2.2458 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4012 - value_mse: 0.1183\n",
            "Epoch 00001: policy_loss did not improve from 2.22137\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0271 - policy_loss: 2.2458 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4012 - value_mse: 0.1183\n",
            "epoch 214\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9880 - policy_loss: 2.2069 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4184 - value_mse: 0.1201\n",
            "Epoch 00001: policy_loss improved from 2.22137 to 2.20686, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 37s 237ms/step - loss: 2.9880 - policy_loss: 2.2069 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4184 - value_mse: 0.1201\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.00460 | Policy loss 2.22376 | Value loss 0.69280 | Policy acc 0.41550 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 215\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0390 - policy_loss: 2.2581 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4105 - value_mse: 0.1176\n",
            "Epoch 00001: policy_loss did not improve from 2.20686\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0390 - policy_loss: 2.2581 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4105 - value_mse: 0.1176\n",
            "epoch 216\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0124 - policy_loss: 2.2317 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4131 - value_mse: 0.1189\n",
            "Epoch 00001: policy_loss did not improve from 2.20686\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 3.0124 - policy_loss: 2.2317 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4131 - value_mse: 0.1189\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.01016 | Policy loss 2.22956 | Value loss 0.69277 | Policy acc 0.41480 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 217\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0166 - policy_loss: 2.2358 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4120 - value_mse: 0.1186\n",
            "Epoch 00001: policy_loss did not improve from 2.20686\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.0166 - policy_loss: 2.2358 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4120 - value_mse: 0.1186\n",
            "epoch 218\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0122 - policy_loss: 2.2320 - value_loss: 0.6926 - policy_categorical_accuracy: 0.4083 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss did not improve from 2.20686\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.0122 - policy_loss: 2.2320 - value_loss: 0.6926 - policy_categorical_accuracy: 0.4083 - value_mse: 0.1185\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.02342 | Policy loss 2.24312 | Value loss 0.69276 | Policy acc 0.41520 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 219\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0046 - policy_loss: 2.2241 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4166 - value_mse: 0.1178\n",
            "Epoch 00001: policy_loss did not improve from 2.20686\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 3.0046 - policy_loss: 2.2241 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4166 - value_mse: 0.1178\n",
            "epoch 220\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0028 - policy_loss: 2.2230 - value_loss: 0.6924 - policy_categorical_accuracy: 0.4148 - value_mse: 0.1192\n",
            "Epoch 00001: policy_loss did not improve from 2.20686\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.0028 - policy_loss: 2.2230 - value_loss: 0.6924 - policy_categorical_accuracy: 0.4148 - value_mse: 0.1192\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.00648 | Policy loss 2.22632 | Value loss 0.69276 | Policy acc 0.41930 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 221\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0257 - policy_loss: 2.2453 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4091 - value_mse: 0.1197\n",
            "Epoch 00001: policy_loss did not improve from 2.20686\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.0257 - policy_loss: 2.2453 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4091 - value_mse: 0.1197\n",
            "epoch 222\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0196 - policy_loss: 2.2395 - value_loss: 0.6926 - policy_categorical_accuracy: 0.4060 - value_mse: 0.1192\n",
            "Epoch 00001: policy_loss did not improve from 2.20686\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.0196 - policy_loss: 2.2395 - value_loss: 0.6926 - policy_categorical_accuracy: 0.4060 - value_mse: 0.1192\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.04861 | Policy loss 2.26843 | Value loss 0.69276 | Policy acc 0.40790 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 223\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0033 - policy_loss: 2.2228 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4092 - value_mse: 0.1190\n",
            "Epoch 00001: policy_loss did not improve from 2.20686\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.0033 - policy_loss: 2.2228 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4092 - value_mse: 0.1190\n",
            "epoch 224\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0084 - policy_loss: 2.2282 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4093 - value_mse: 0.1162\n",
            "Epoch 00001: policy_loss did not improve from 2.20686\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.0084 - policy_loss: 2.2282 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4093 - value_mse: 0.1162\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.00099 | Policy loss 2.22112 | Value loss 0.69280 | Policy acc 0.41530 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 225\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0071 - policy_loss: 2.2268 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4168 - value_mse: 0.1170\n",
            "Epoch 00001: policy_loss did not improve from 2.20686\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.0071 - policy_loss: 2.2268 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4168 - value_mse: 0.1170\n",
            "epoch 226\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9880 - policy_loss: 2.2082 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4131 - value_mse: 0.1171\n",
            "Epoch 00001: policy_loss did not improve from 2.20686\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9880 - policy_loss: 2.2082 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4131 - value_mse: 0.1171\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.99960 | Policy loss 2.21983 | Value loss 0.69276 | Policy acc 0.42040 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 227\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9837 - policy_loss: 2.2040 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4176 - value_mse: 0.1178\n",
            "Epoch 00001: policy_loss improved from 2.20686 to 2.20397, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 2.9837 - policy_loss: 2.2040 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4176 - value_mse: 0.1178\n",
            "epoch 228\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9927 - policy_loss: 2.2127 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4160 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss did not improve from 2.20397\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9927 - policy_loss: 2.2127 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4160 - value_mse: 0.1191\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.01373 | Policy loss 2.23418 | Value loss 0.69277 | Policy acc 0.41920 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 229\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9863 - policy_loss: 2.2065 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4152 - value_mse: 0.1201\n",
            "Epoch 00001: policy_loss did not improve from 2.20397\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9863 - policy_loss: 2.2065 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4152 - value_mse: 0.1201\n",
            "epoch 230\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9975 - policy_loss: 2.2180 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4173 - value_mse: 0.1180\n",
            "Epoch 00001: policy_loss did not improve from 2.20397\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9975 - policy_loss: 2.2180 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4173 - value_mse: 0.1180\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.00592 | Policy loss 2.22666 | Value loss 0.69279 | Policy acc 0.41870 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 231\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0277 - policy_loss: 2.2483 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4081 - value_mse: 0.1168\n",
            "Epoch 00001: policy_loss did not improve from 2.20397\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.0277 - policy_loss: 2.2483 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4081 - value_mse: 0.1168\n",
            "epoch 232\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9833 - policy_loss: 2.2039 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4179 - value_mse: 0.1171\n",
            "Epoch 00001: policy_loss improved from 2.20397 to 2.20388, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 2.9833 - policy_loss: 2.2039 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4179 - value_mse: 0.1171\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.99864 | Policy loss 2.21946 | Value loss 0.69280 | Policy acc 0.41910 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 233\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0020 - policy_loss: 2.2228 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4070 - value_mse: 0.1193\n",
            "Epoch 00001: policy_loss did not improve from 2.20388\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.0020 - policy_loss: 2.2228 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4070 - value_mse: 0.1193\n",
            "epoch 234\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9998 - policy_loss: 2.2208 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4120 - value_mse: 0.1164\n",
            "Epoch 00001: policy_loss did not improve from 2.20388\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9998 - policy_loss: 2.2208 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4120 - value_mse: 0.1164\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.99453 | Policy loss 2.21545 | Value loss 0.69277 | Policy acc 0.41830 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 235\n",
            "157/157 [==============================] - ETA: 0s - loss: 3.0302 - policy_loss: 2.2506 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4120 - value_mse: 0.1176\n",
            "Epoch 00001: policy_loss did not improve from 2.20388\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 3.0302 - policy_loss: 2.2506 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4120 - value_mse: 0.1176\n",
            "epoch 236\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9720 - policy_loss: 2.1928 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4188 - value_mse: 0.1186\n",
            "Epoch 00001: policy_loss improved from 2.20388 to 2.19285, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 2.9720 - policy_loss: 2.1928 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4188 - value_mse: 0.1186\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.98581 | Policy loss 2.20674 | Value loss 0.69278 | Policy acc 0.42110 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 237\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9784 - policy_loss: 2.1990 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4210 - value_mse: 0.1214\n",
            "Epoch 00001: policy_loss did not improve from 2.19285\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9784 - policy_loss: 2.1990 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4210 - value_mse: 0.1214\n",
            "epoch 238\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9887 - policy_loss: 2.2096 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4169 - value_mse: 0.1197\n",
            "Epoch 00001: policy_loss did not improve from 2.19285\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9887 - policy_loss: 2.2096 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4169 - value_mse: 0.1197\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.97873 | Policy loss 2.19993 | Value loss 0.69283 | Policy acc 0.42220 | Value MSE 0.11724 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 239\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9780 - policy_loss: 2.1992 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4174 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 2.19285\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9780 - policy_loss: 2.1992 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4174 - value_mse: 0.1177\n",
            "epoch 240\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9581 - policy_loss: 2.1792 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4210 - value_mse: 0.1174\n",
            "Epoch 00001: policy_loss improved from 2.19285 to 2.17915, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 2.9581 - policy_loss: 2.1792 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4210 - value_mse: 0.1174\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.98331 | Policy loss 2.20447 | Value loss 0.69277 | Policy acc 0.41880 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 241\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9829 - policy_loss: 2.2038 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4143 - value_mse: 0.1168\n",
            "Epoch 00001: policy_loss did not improve from 2.17915\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9829 - policy_loss: 2.2038 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4143 - value_mse: 0.1168\n",
            "epoch 242\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9669 - policy_loss: 2.1880 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4227 - value_mse: 0.1189\n",
            "Epoch 00001: policy_loss did not improve from 2.17915\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9669 - policy_loss: 2.1880 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4227 - value_mse: 0.1189\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.98866 | Policy loss 2.20995 | Value loss 0.69282 | Policy acc 0.41970 | Value MSE 0.11724 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 243\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9659 - policy_loss: 2.1870 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4121 - value_mse: 0.1158\n",
            "Epoch 00001: policy_loss did not improve from 2.17915\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9659 - policy_loss: 2.1870 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4121 - value_mse: 0.1158\n",
            "epoch 244\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9621 - policy_loss: 2.1834 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4262 - value_mse: 0.1192\n",
            "Epoch 00001: policy_loss did not improve from 2.17915\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9621 - policy_loss: 2.1834 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4262 - value_mse: 0.1192\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.99145 | Policy loss 2.21300 | Value loss 0.69283 | Policy acc 0.41730 | Value MSE 0.11724 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 245\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9739 - policy_loss: 2.1954 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4133 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss did not improve from 2.17915\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9739 - policy_loss: 2.1954 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4133 - value_mse: 0.1185\n",
            "epoch 246\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9935 - policy_loss: 2.2150 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4097 - value_mse: 0.1172\n",
            "Epoch 00001: policy_loss did not improve from 2.17915\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9935 - policy_loss: 2.2150 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4097 - value_mse: 0.1172\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.96577 | Policy loss 2.18748 | Value loss 0.69281 | Policy acc 0.42260 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 247\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9957 - policy_loss: 2.2174 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4161 - value_mse: 0.1186\n",
            "Epoch 00001: policy_loss did not improve from 2.17915\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.9957 - policy_loss: 2.2174 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4161 - value_mse: 0.1186\n",
            "epoch 248\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9723 - policy_loss: 2.1941 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4229 - value_mse: 0.1186\n",
            "Epoch 00001: policy_loss did not improve from 2.17915\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9723 - policy_loss: 2.1941 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4229 - value_mse: 0.1186\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.96081 | Policy loss 2.18282 | Value loss 0.69278 | Policy acc 0.42100 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 249\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9640 - policy_loss: 2.1859 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4181 - value_mse: 0.1189\n",
            "Epoch 00001: policy_loss did not improve from 2.17915\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.9640 - policy_loss: 2.1859 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4181 - value_mse: 0.1189\n",
            "epoch 250\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9833 - policy_loss: 2.2051 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4167 - value_mse: 0.1187\n",
            "Epoch 00001: policy_loss did not improve from 2.17915\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9833 - policy_loss: 2.2051 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4167 - value_mse: 0.1187\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 3.01186 | Policy loss 2.23391 | Value loss 0.69279 | Policy acc 0.41660 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 251\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9396 - policy_loss: 2.1613 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4277 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss improved from 2.17915 to 2.16134, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 230ms/step - loss: 2.9396 - policy_loss: 2.1613 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4277 - value_mse: 0.1185\n",
            "epoch 252\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9618 - policy_loss: 2.1837 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4208 - value_mse: 0.1174\n",
            "Epoch 00001: policy_loss did not improve from 2.16134\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9618 - policy_loss: 2.1837 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4208 - value_mse: 0.1174\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.97429 | Policy loss 2.19647 | Value loss 0.69281 | Policy acc 0.41940 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 253\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9565 - policy_loss: 2.1785 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4161 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 2.16134\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9565 - policy_loss: 2.1785 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4161 - value_mse: 0.1177\n",
            "epoch 254\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9655 - policy_loss: 2.1880 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4166 - value_mse: 0.1173\n",
            "Epoch 00001: policy_loss did not improve from 2.16134\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9655 - policy_loss: 2.1880 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4166 - value_mse: 0.1173\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.96705 | Policy loss 2.18956 | Value loss 0.69278 | Policy acc 0.42280 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 255\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9816 - policy_loss: 2.2039 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4162 - value_mse: 0.1176\n",
            "Epoch 00001: policy_loss did not improve from 2.16134\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9816 - policy_loss: 2.2039 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4162 - value_mse: 0.1176\n",
            "epoch 256\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9559 - policy_loss: 2.1783 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4239 - value_mse: 0.1200\n",
            "Epoch 00001: policy_loss did not improve from 2.16134\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.9559 - policy_loss: 2.1783 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4239 - value_mse: 0.1200\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.97735 | Policy loss 2.19990 | Value loss 0.69278 | Policy acc 0.41850 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 257\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9679 - policy_loss: 2.1903 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4176 - value_mse: 0.1171\n",
            "Epoch 00001: policy_loss did not improve from 2.16134\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9679 - policy_loss: 2.1903 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4176 - value_mse: 0.1171\n",
            "epoch 258\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9570 - policy_loss: 2.1796 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4236 - value_mse: 0.1168\n",
            "Epoch 00001: policy_loss did not improve from 2.16134\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.9570 - policy_loss: 2.1796 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4236 - value_mse: 0.1168\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.96307 | Policy loss 2.18590 | Value loss 0.69278 | Policy acc 0.42130 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 259\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9695 - policy_loss: 2.1922 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4178 - value_mse: 0.1155\n",
            "Epoch 00001: policy_loss did not improve from 2.16134\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.9695 - policy_loss: 2.1922 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4178 - value_mse: 0.1155\n",
            "epoch 260\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9345 - policy_loss: 2.1574 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4259 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss improved from 2.16134 to 2.15738, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 233ms/step - loss: 2.9345 - policy_loss: 2.1574 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4259 - value_mse: 0.1184\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.96628 | Policy loss 2.18913 | Value loss 0.69276 | Policy acc 0.42370 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 261\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9732 - policy_loss: 2.1959 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4218 - value_mse: 0.1159\n",
            "Epoch 00001: policy_loss did not improve from 2.15738\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9732 - policy_loss: 2.1959 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4218 - value_mse: 0.1159\n",
            "epoch 262\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9594 - policy_loss: 2.1823 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4208 - value_mse: 0.1174\n",
            "Epoch 00001: policy_loss did not improve from 2.15738\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9594 - policy_loss: 2.1823 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4208 - value_mse: 0.1174\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.95192 | Policy loss 2.17495 | Value loss 0.69276 | Policy acc 0.42580 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 263\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9556 - policy_loss: 2.1785 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4164 - value_mse: 0.1167\n",
            "Epoch 00001: policy_loss did not improve from 2.15738\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9556 - policy_loss: 2.1785 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4164 - value_mse: 0.1167\n",
            "epoch 264\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9593 - policy_loss: 2.1826 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4148 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 2.15738\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9593 - policy_loss: 2.1826 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4148 - value_mse: 0.1177\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.96931 | Policy loss 2.19259 | Value loss 0.69276 | Policy acc 0.42060 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 265\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9553 - policy_loss: 2.1785 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4161 - value_mse: 0.1187\n",
            "Epoch 00001: policy_loss did not improve from 2.15738\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9553 - policy_loss: 2.1785 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4161 - value_mse: 0.1187\n",
            "epoch 266\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9778 - policy_loss: 2.2009 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4196 - value_mse: 0.1176\n",
            "Epoch 00001: policy_loss did not improve from 2.15738\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9778 - policy_loss: 2.2009 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4196 - value_mse: 0.1176\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.95048 | Policy loss 2.17382 | Value loss 0.69277 | Policy acc 0.42550 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 267\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9427 - policy_loss: 2.1659 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4256 - value_mse: 0.1207\n",
            "Epoch 00001: policy_loss did not improve from 2.15738\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9427 - policy_loss: 2.1659 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4256 - value_mse: 0.1207\n",
            "epoch 268\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9465 - policy_loss: 2.1697 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4240 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss did not improve from 2.15738\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9465 - policy_loss: 2.1697 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4240 - value_mse: 0.1185\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.94279 | Policy loss 2.16637 | Value loss 0.69281 | Policy acc 0.42660 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 269\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9532 - policy_loss: 2.1766 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4156 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss did not improve from 2.15738\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9532 - policy_loss: 2.1766 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4156 - value_mse: 0.1191\n",
            "epoch 270\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9245 - policy_loss: 2.1481 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4312 - value_mse: 0.1196\n",
            "Epoch 00001: policy_loss improved from 2.15738 to 2.14811, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 2.9245 - policy_loss: 2.1481 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4312 - value_mse: 0.1196\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.94206 | Policy loss 2.16568 | Value loss 0.69277 | Policy acc 0.42780 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 271\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9469 - policy_loss: 2.1709 - value_loss: 0.6926 - policy_categorical_accuracy: 0.4251 - value_mse: 0.1189\n",
            "Epoch 00001: policy_loss did not improve from 2.14811\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9469 - policy_loss: 2.1709 - value_loss: 0.6926 - policy_categorical_accuracy: 0.4251 - value_mse: 0.1189\n",
            "epoch 272\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9537 - policy_loss: 2.1772 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4201 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss did not improve from 2.14811\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9537 - policy_loss: 2.1772 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4201 - value_mse: 0.1191\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.94079 | Policy loss 2.16460 | Value loss 0.69276 | Policy acc 0.42430 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 273\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9451 - policy_loss: 2.1692 - value_loss: 0.6925 - policy_categorical_accuracy: 0.4203 - value_mse: 0.1198\n",
            "Epoch 00001: policy_loss did not improve from 2.14811\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9451 - policy_loss: 2.1692 - value_loss: 0.6925 - policy_categorical_accuracy: 0.4203 - value_mse: 0.1198\n",
            "epoch 274\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9345 - policy_loss: 2.1583 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4249 - value_mse: 0.1173\n",
            "Epoch 00001: policy_loss did not improve from 2.14811\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9345 - policy_loss: 2.1583 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4249 - value_mse: 0.1173\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.94130 | Policy loss 2.16538 | Value loss 0.69276 | Policy acc 0.42540 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 275\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9191 - policy_loss: 2.1429 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4274 - value_mse: 0.1180\n",
            "Epoch 00001: policy_loss improved from 2.14811 to 2.14294, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 2.9191 - policy_loss: 2.1429 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4274 - value_mse: 0.1180\n",
            "epoch 276\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9487 - policy_loss: 2.1727 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4202 - value_mse: 0.1193\n",
            "Epoch 00001: policy_loss did not improve from 2.14294\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9487 - policy_loss: 2.1727 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4202 - value_mse: 0.1193\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.92517 | Policy loss 2.14939 | Value loss 0.69277 | Policy acc 0.43050 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 277\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9425 - policy_loss: 2.1666 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4212 - value_mse: 0.1199\n",
            "Epoch 00001: policy_loss did not improve from 2.14294\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9425 - policy_loss: 2.1666 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4212 - value_mse: 0.1199\n",
            "epoch 278\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9407 - policy_loss: 2.1647 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4188 - value_mse: 0.1183\n",
            "Epoch 00001: policy_loss did not improve from 2.14294\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9407 - policy_loss: 2.1647 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4188 - value_mse: 0.1183\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.93445 | Policy loss 2.15883 | Value loss 0.69278 | Policy acc 0.43210 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 279\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9346 - policy_loss: 2.1591 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4206 - value_mse: 0.1192\n",
            "Epoch 00001: policy_loss did not improve from 2.14294\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9346 - policy_loss: 2.1591 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4206 - value_mse: 0.1192\n",
            "epoch 280\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9576 - policy_loss: 2.1822 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4197 - value_mse: 0.1178\n",
            "Epoch 00001: policy_loss did not improve from 2.14294\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9576 - policy_loss: 2.1822 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4197 - value_mse: 0.1178\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.93332 | Policy loss 2.15787 | Value loss 0.69276 | Policy acc 0.42830 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 281\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9263 - policy_loss: 2.1508 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4232 - value_mse: 0.1163\n",
            "Epoch 00001: policy_loss did not improve from 2.14294\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9263 - policy_loss: 2.1508 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4232 - value_mse: 0.1163\n",
            "epoch 282\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9587 - policy_loss: 2.1830 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4205 - value_mse: 0.1195\n",
            "Epoch 00001: policy_loss did not improve from 2.14294\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9587 - policy_loss: 2.1830 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4205 - value_mse: 0.1195\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.94247 | Policy loss 2.16684 | Value loss 0.69277 | Policy acc 0.42680 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 283\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9364 - policy_loss: 2.1607 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4222 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss did not improve from 2.14294\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9364 - policy_loss: 2.1607 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4222 - value_mse: 0.1191\n",
            "epoch 284\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9432 - policy_loss: 2.1677 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4274 - value_mse: 0.1176\n",
            "Epoch 00001: policy_loss did not improve from 2.14294\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9432 - policy_loss: 2.1677 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4274 - value_mse: 0.1176\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.93969 | Policy loss 2.16438 | Value loss 0.69277 | Policy acc 0.43080 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 285\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9204 - policy_loss: 2.1451 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4285 - value_mse: 0.1173\n",
            "Epoch 00001: policy_loss did not improve from 2.14294\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9204 - policy_loss: 2.1451 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4285 - value_mse: 0.1173\n",
            "epoch 286\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9446 - policy_loss: 2.1692 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4272 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss did not improve from 2.14294\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9446 - policy_loss: 2.1692 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4272 - value_mse: 0.1191\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.93059 | Policy loss 2.15551 | Value loss 0.69279 | Policy acc 0.43360 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 287\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9231 - policy_loss: 2.1478 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4258 - value_mse: 0.1196\n",
            "Epoch 00001: policy_loss did not improve from 2.14294\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9231 - policy_loss: 2.1478 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4258 - value_mse: 0.1196\n",
            "epoch 288\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9119 - policy_loss: 2.1368 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4296 - value_mse: 0.1176\n",
            "Epoch 00001: policy_loss improved from 2.14294 to 2.13682, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 2.9119 - policy_loss: 2.1368 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4296 - value_mse: 0.1176\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.93074 | Policy loss 2.15588 | Value loss 0.69279 | Policy acc 0.42780 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 289\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9297 - policy_loss: 2.1548 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4168 - value_mse: 0.1197\n",
            "Epoch 00001: policy_loss did not improve from 2.13682\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9297 - policy_loss: 2.1548 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4168 - value_mse: 0.1197\n",
            "epoch 290\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9002 - policy_loss: 2.1255 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4274 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss improved from 2.13682 to 2.12553, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 2.9002 - policy_loss: 2.1255 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4274 - value_mse: 0.1177\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.92915 | Policy loss 2.15453 | Value loss 0.69277 | Policy acc 0.42400 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 291\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9122 - policy_loss: 2.1374 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4303 - value_mse: 0.1183\n",
            "Epoch 00001: policy_loss did not improve from 2.12553\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9122 - policy_loss: 2.1374 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4303 - value_mse: 0.1183\n",
            "epoch 292\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9128 - policy_loss: 2.1382 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4262 - value_mse: 0.1206\n",
            "Epoch 00001: policy_loss did not improve from 2.12553\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9128 - policy_loss: 2.1382 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4262 - value_mse: 0.1206\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.92743 | Policy loss 2.15299 | Value loss 0.69277 | Policy acc 0.43120 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 293\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9292 - policy_loss: 2.1549 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4266 - value_mse: 0.1183\n",
            "Epoch 00001: policy_loss did not improve from 2.12553\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9292 - policy_loss: 2.1549 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4266 - value_mse: 0.1183\n",
            "epoch 294\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9499 - policy_loss: 2.1754 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4195 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 2.12553\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9499 - policy_loss: 2.1754 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4195 - value_mse: 0.1182\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.93084 | Policy loss 2.15649 | Value loss 0.69276 | Policy acc 0.42510 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 295\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9205 - policy_loss: 2.1462 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4251 - value_mse: 0.1183\n",
            "Epoch 00001: policy_loss did not improve from 2.12553\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9205 - policy_loss: 2.1462 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4251 - value_mse: 0.1183\n",
            "epoch 296\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9140 - policy_loss: 2.1396 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4259 - value_mse: 0.1208\n",
            "Epoch 00001: policy_loss did not improve from 2.12553\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9140 - policy_loss: 2.1396 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4259 - value_mse: 0.1208\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.93497 | Policy loss 2.16085 | Value loss 0.69276 | Policy acc 0.43390 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 297\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9099 - policy_loss: 2.1357 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4247 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss did not improve from 2.12553\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9099 - policy_loss: 2.1357 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4247 - value_mse: 0.1185\n",
            "epoch 298\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9259 - policy_loss: 2.1519 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4224 - value_mse: 0.1180\n",
            "Epoch 00001: policy_loss did not improve from 2.12553\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9259 - policy_loss: 2.1519 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4224 - value_mse: 0.1180\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.92169 | Policy loss 2.14777 | Value loss 0.69276 | Policy acc 0.42900 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 299\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9198 - policy_loss: 2.1462 - value_loss: 0.6925 - policy_categorical_accuracy: 0.4333 - value_mse: 0.1196\n",
            "Epoch 00001: policy_loss did not improve from 2.12553\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9198 - policy_loss: 2.1462 - value_loss: 0.6925 - policy_categorical_accuracy: 0.4333 - value_mse: 0.1196\n",
            "epoch 300\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9403 - policy_loss: 2.1663 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4246 - value_mse: 0.1167\n",
            "Epoch 00001: policy_loss did not improve from 2.12553\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.9403 - policy_loss: 2.1663 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4246 - value_mse: 0.1167\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.89969 | Policy loss 2.12592 | Value loss 0.69276 | Policy acc 0.43550 | Value MSE 0.11720 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 301\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9192 - policy_loss: 2.1453 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4270 - value_mse: 0.1176\n",
            "Epoch 00001: policy_loss did not improve from 2.12553\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9192 - policy_loss: 2.1453 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4270 - value_mse: 0.1176\n",
            "epoch 302\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9346 - policy_loss: 2.1607 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4203 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss did not improve from 2.12553\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9346 - policy_loss: 2.1607 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4203 - value_mse: 0.1191\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.91127 | Policy loss 2.13767 | Value loss 0.69277 | Policy acc 0.43060 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 303\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9132 - policy_loss: 2.1394 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4255 - value_mse: 0.1179\n",
            "Epoch 00001: policy_loss did not improve from 2.12553\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9132 - policy_loss: 2.1394 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4255 - value_mse: 0.1179\n",
            "epoch 304\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9377 - policy_loss: 2.1640 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4237 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss did not improve from 2.12553\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9377 - policy_loss: 2.1640 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4237 - value_mse: 0.1184\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.89949 | Policy loss 2.12605 | Value loss 0.69278 | Policy acc 0.43180 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 305\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8946 - policy_loss: 2.1211 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4306 - value_mse: 0.1173\n",
            "Epoch 00001: policy_loss improved from 2.12553 to 2.12106, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 2.8946 - policy_loss: 2.1211 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4306 - value_mse: 0.1173\n",
            "epoch 306\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8748 - policy_loss: 2.1011 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4273 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss improved from 2.12106 to 2.10113, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 231ms/step - loss: 2.8748 - policy_loss: 2.1011 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4273 - value_mse: 0.1191\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.90919 | Policy loss 2.13583 | Value loss 0.69279 | Policy acc 0.43340 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 307\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9059 - policy_loss: 2.1324 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4306 - value_mse: 0.1168\n",
            "Epoch 00001: policy_loss did not improve from 2.10113\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.9059 - policy_loss: 2.1324 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4306 - value_mse: 0.1168\n",
            "epoch 308\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8600 - policy_loss: 2.0867 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4400 - value_mse: 0.1179\n",
            "Epoch 00001: policy_loss improved from 2.10113 to 2.08673, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 2.8600 - policy_loss: 2.0867 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4400 - value_mse: 0.1179\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.90118 | Policy loss 2.12803 | Value loss 0.69277 | Policy acc 0.43240 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 309\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9188 - policy_loss: 2.1455 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4315 - value_mse: 0.1189\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9188 - policy_loss: 2.1455 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4315 - value_mse: 0.1189\n",
            "epoch 310\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9116 - policy_loss: 2.1384 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4243 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9116 - policy_loss: 2.1384 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4243 - value_mse: 0.1191\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.90074 | Policy loss 2.12776 | Value loss 0.69277 | Policy acc 0.43170 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 311\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8894 - policy_loss: 2.1163 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4348 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8894 - policy_loss: 2.1163 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4348 - value_mse: 0.1181\n",
            "epoch 312\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9018 - policy_loss: 2.1288 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4301 - value_mse: 0.1188\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9018 - policy_loss: 2.1288 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4301 - value_mse: 0.1188\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.90346 | Policy loss 2.13067 | Value loss 0.69277 | Policy acc 0.43260 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 313\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8925 - policy_loss: 2.1199 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4257 - value_mse: 0.1188\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8925 - policy_loss: 2.1199 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4257 - value_mse: 0.1188\n",
            "epoch 314\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8882 - policy_loss: 2.1151 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4353 - value_mse: 0.1210\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8882 - policy_loss: 2.1151 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4353 - value_mse: 0.1210\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.89416 | Policy loss 2.12156 | Value loss 0.69278 | Policy acc 0.43010 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 315\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9018 - policy_loss: 2.1290 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4299 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9018 - policy_loss: 2.1290 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4299 - value_mse: 0.1182\n",
            "epoch 316\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9056 - policy_loss: 2.1329 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4277 - value_mse: 0.1198\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9056 - policy_loss: 2.1329 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4277 - value_mse: 0.1198\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.91233 | Policy loss 2.13979 | Value loss 0.69279 | Policy acc 0.43220 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 317\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8759 - policy_loss: 2.1031 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4347 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8759 - policy_loss: 2.1031 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4347 - value_mse: 0.1177\n",
            "epoch 318\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9052 - policy_loss: 2.1325 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4299 - value_mse: 0.1174\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9052 - policy_loss: 2.1325 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4299 - value_mse: 0.1174\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.89630 | Policy loss 2.12390 | Value loss 0.69281 | Policy acc 0.43640 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 319\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9042 - policy_loss: 2.1316 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4325 - value_mse: 0.1193\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9042 - policy_loss: 2.1316 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4325 - value_mse: 0.1193\n",
            "epoch 320\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9134 - policy_loss: 2.1413 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4264 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9134 - policy_loss: 2.1413 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4264 - value_mse: 0.1184\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.88382 | Policy loss 2.11164 | Value loss 0.69278 | Policy acc 0.43600 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 321\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8885 - policy_loss: 2.1160 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4297 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8885 - policy_loss: 2.1160 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4297 - value_mse: 0.1185\n",
            "epoch 322\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9120 - policy_loss: 2.1401 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4306 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9120 - policy_loss: 2.1401 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4306 - value_mse: 0.1182\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.89283 | Policy loss 2.12087 | Value loss 0.69277 | Policy acc 0.43340 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 323\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9003 - policy_loss: 2.1281 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4294 - value_mse: 0.1193\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9003 - policy_loss: 2.1281 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4294 - value_mse: 0.1193\n",
            "epoch 324\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8802 - policy_loss: 2.1079 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4351 - value_mse: 0.1201\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8802 - policy_loss: 2.1079 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4351 - value_mse: 0.1201\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.88972 | Policy loss 2.11780 | Value loss 0.69278 | Policy acc 0.43480 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 325\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9103 - policy_loss: 2.1385 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4289 - value_mse: 0.1175\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9103 - policy_loss: 2.1385 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4289 - value_mse: 0.1175\n",
            "epoch 326\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8887 - policy_loss: 2.1167 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4314 - value_mse: 0.1169\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8887 - policy_loss: 2.1167 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4314 - value_mse: 0.1169\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.88388 | Policy loss 2.11218 | Value loss 0.69277 | Policy acc 0.43700 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 327\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8837 - policy_loss: 2.1118 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4349 - value_mse: 0.1183\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8837 - policy_loss: 2.1118 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4349 - value_mse: 0.1183\n",
            "epoch 328\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8751 - policy_loss: 2.1032 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4349 - value_mse: 0.1193\n",
            "Epoch 00001: policy_loss did not improve from 2.08673\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8751 - policy_loss: 2.1032 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4349 - value_mse: 0.1193\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.87926 | Policy loss 2.10767 | Value loss 0.69279 | Policy acc 0.43890 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 329\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8548 - policy_loss: 2.0832 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4353 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss improved from 2.08673 to 2.08324, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 2.8548 - policy_loss: 2.0832 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4353 - value_mse: 0.1177\n",
            "epoch 330\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8610 - policy_loss: 2.0896 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4339 - value_mse: 0.1197\n",
            "Epoch 00001: policy_loss did not improve from 2.08324\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8610 - policy_loss: 2.0896 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4339 - value_mse: 0.1197\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.88476 | Policy loss 2.11339 | Value loss 0.69277 | Policy acc 0.43470 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 331\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8743 - policy_loss: 2.1026 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4338 - value_mse: 0.1193\n",
            "Epoch 00001: policy_loss did not improve from 2.08324\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8743 - policy_loss: 2.1026 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4338 - value_mse: 0.1193\n",
            "epoch 332\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8745 - policy_loss: 2.1032 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4385 - value_mse: 0.1160\n",
            "Epoch 00001: policy_loss did not improve from 2.08324\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8745 - policy_loss: 2.1032 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4385 - value_mse: 0.1160\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.87518 | Policy loss 2.10398 | Value loss 0.69277 | Policy acc 0.43460 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 333\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8743 - policy_loss: 2.1029 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4370 - value_mse: 0.1202\n",
            "Epoch 00001: policy_loss did not improve from 2.08324\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8743 - policy_loss: 2.1029 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4370 - value_mse: 0.1202\n",
            "epoch 334\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8817 - policy_loss: 2.1107 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4302 - value_mse: 0.1170\n",
            "Epoch 00001: policy_loss did not improve from 2.08324\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.8817 - policy_loss: 2.1107 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4302 - value_mse: 0.1170\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.88419 | Policy loss 2.11315 | Value loss 0.69277 | Policy acc 0.43340 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 335\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8588 - policy_loss: 2.0880 - value_loss: 0.6926 - policy_categorical_accuracy: 0.4339 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss did not improve from 2.08324\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8588 - policy_loss: 2.0880 - value_loss: 0.6926 - policy_categorical_accuracy: 0.4339 - value_mse: 0.1181\n",
            "epoch 336\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9043 - policy_loss: 2.1330 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4257 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss did not improve from 2.08324\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9043 - policy_loss: 2.1330 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4257 - value_mse: 0.1185\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.86841 | Policy loss 2.09756 | Value loss 0.69277 | Policy acc 0.43670 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 337\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8901 - policy_loss: 2.1192 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4240 - value_mse: 0.1198\n",
            "Epoch 00001: policy_loss did not improve from 2.08324\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8901 - policy_loss: 2.1192 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4240 - value_mse: 0.1198\n",
            "epoch 338\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8844 - policy_loss: 2.1136 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4372 - value_mse: 0.1165\n",
            "Epoch 00001: policy_loss did not improve from 2.08324\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8844 - policy_loss: 2.1136 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4372 - value_mse: 0.1165\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.88504 | Policy loss 2.11431 | Value loss 0.69277 | Policy acc 0.43490 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 339\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8485 - policy_loss: 2.0776 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4353 - value_mse: 0.1176\n",
            "Epoch 00001: policy_loss improved from 2.08324 to 2.07759, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 2.8485 - policy_loss: 2.0776 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4353 - value_mse: 0.1176\n",
            "epoch 340\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8686 - policy_loss: 2.0978 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4352 - value_mse: 0.1198\n",
            "Epoch 00001: policy_loss did not improve from 2.07759\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8686 - policy_loss: 2.0978 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4352 - value_mse: 0.1198\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.86839 | Policy loss 2.09779 | Value loss 0.69278 | Policy acc 0.43660 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 341\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8576 - policy_loss: 2.0869 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4297 - value_mse: 0.1178\n",
            "Epoch 00001: policy_loss did not improve from 2.07759\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8576 - policy_loss: 2.0869 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4297 - value_mse: 0.1178\n",
            "epoch 342\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9178 - policy_loss: 2.1471 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4251 - value_mse: 0.1180\n",
            "Epoch 00001: policy_loss did not improve from 2.07759\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.9178 - policy_loss: 2.1471 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4251 - value_mse: 0.1180\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.87258 | Policy loss 2.10213 | Value loss 0.69278 | Policy acc 0.43650 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 343\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8500 - policy_loss: 2.0797 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4391 - value_mse: 0.1171\n",
            "Epoch 00001: policy_loss did not improve from 2.07759\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8500 - policy_loss: 2.0797 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4391 - value_mse: 0.1171\n",
            "epoch 344\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8757 - policy_loss: 2.1051 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4293 - value_mse: 0.1174\n",
            "Epoch 00001: policy_loss did not improve from 2.07759\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8757 - policy_loss: 2.1051 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4293 - value_mse: 0.1174\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.86762 | Policy loss 2.09727 | Value loss 0.69278 | Policy acc 0.43690 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 345\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8869 - policy_loss: 2.1163 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4299 - value_mse: 0.1178\n",
            "Epoch 00001: policy_loss did not improve from 2.07759\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8869 - policy_loss: 2.1163 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4299 - value_mse: 0.1178\n",
            "epoch 346\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8598 - policy_loss: 2.0893 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4315 - value_mse: 0.1171\n",
            "Epoch 00001: policy_loss did not improve from 2.07759\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8598 - policy_loss: 2.0893 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4315 - value_mse: 0.1171\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.86502 | Policy loss 2.09482 | Value loss 0.69279 | Policy acc 0.43780 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 347\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8566 - policy_loss: 2.0862 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4305 - value_mse: 0.1173\n",
            "Epoch 00001: policy_loss did not improve from 2.07759\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8566 - policy_loss: 2.0862 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4305 - value_mse: 0.1173\n",
            "epoch 348\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8613 - policy_loss: 2.0910 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4347 - value_mse: 0.1194\n",
            "Epoch 00001: policy_loss did not improve from 2.07759\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8613 - policy_loss: 2.0910 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4347 - value_mse: 0.1194\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.86389 | Policy loss 2.09381 | Value loss 0.69279 | Policy acc 0.43520 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 349\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8371 - policy_loss: 2.0670 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4350 - value_mse: 0.1179\n",
            "Epoch 00001: policy_loss improved from 2.07759 to 2.06695, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 2.8371 - policy_loss: 2.0670 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4350 - value_mse: 0.1179\n",
            "epoch 350\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8571 - policy_loss: 2.0873 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4327 - value_mse: 0.1179\n",
            "Epoch 00001: policy_loss did not improve from 2.06695\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8571 - policy_loss: 2.0873 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4327 - value_mse: 0.1179\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.86203 | Policy loss 2.09215 | Value loss 0.69277 | Policy acc 0.43390 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 351\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8831 - policy_loss: 2.1128 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4308 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 2.06695\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8831 - policy_loss: 2.1128 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4308 - value_mse: 0.1182\n",
            "epoch 352\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8405 - policy_loss: 2.0707 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4394 - value_mse: 0.1169\n",
            "Epoch 00001: policy_loss did not improve from 2.06695\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8405 - policy_loss: 2.0707 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4394 - value_mse: 0.1169\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.85629 | Policy loss 2.08656 | Value loss 0.69277 | Policy acc 0.44080 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 353\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8652 - policy_loss: 2.0953 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4326 - value_mse: 0.1175\n",
            "Epoch 00001: policy_loss did not improve from 2.06695\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8652 - policy_loss: 2.0953 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4326 - value_mse: 0.1175\n",
            "epoch 354\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8434 - policy_loss: 2.0737 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4394 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss did not improve from 2.06695\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8434 - policy_loss: 2.0737 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4394 - value_mse: 0.1181\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.86225 | Policy loss 2.09265 | Value loss 0.69277 | Policy acc 0.43660 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 355\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8865 - policy_loss: 2.1169 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4273 - value_mse: 0.1196\n",
            "Epoch 00001: policy_loss did not improve from 2.06695\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8865 - policy_loss: 2.1169 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4273 - value_mse: 0.1196\n",
            "epoch 356\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8404 - policy_loss: 2.0708 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4381 - value_mse: 0.1165\n",
            "Epoch 00001: policy_loss did not improve from 2.06695\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8404 - policy_loss: 2.0708 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4381 - value_mse: 0.1165\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.86086 | Policy loss 2.09136 | Value loss 0.69277 | Policy acc 0.43670 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 357\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.9143 - policy_loss: 2.1447 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4195 - value_mse: 0.1187\n",
            "Epoch 00001: policy_loss did not improve from 2.06695\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.9143 - policy_loss: 2.1447 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4195 - value_mse: 0.1187\n",
            "epoch 358\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8548 - policy_loss: 2.0850 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4317 - value_mse: 0.1167\n",
            "Epoch 00001: policy_loss did not improve from 2.06695\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8548 - policy_loss: 2.0850 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4317 - value_mse: 0.1167\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.84955 | Policy loss 2.08016 | Value loss 0.69278 | Policy acc 0.43980 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 359\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8481 - policy_loss: 2.0787 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4364 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss did not improve from 2.06695\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8481 - policy_loss: 2.0787 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4364 - value_mse: 0.1191\n",
            "epoch 360\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8249 - policy_loss: 2.0554 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4359 - value_mse: 0.1175\n",
            "Epoch 00001: policy_loss improved from 2.06695 to 2.05536, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 2.8249 - policy_loss: 2.0554 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4359 - value_mse: 0.1175\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.85024 | Policy loss 2.08099 | Value loss 0.69278 | Policy acc 0.43850 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 361\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8639 - policy_loss: 2.0945 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4327 - value_mse: 0.1197\n",
            "Epoch 00001: policy_loss did not improve from 2.05536\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8639 - policy_loss: 2.0945 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4327 - value_mse: 0.1197\n",
            "epoch 362\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8843 - policy_loss: 2.1149 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4328 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss did not improve from 2.05536\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8843 - policy_loss: 2.1149 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4328 - value_mse: 0.1181\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.85400 | Policy loss 2.08483 | Value loss 0.69278 | Policy acc 0.43480 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 363\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8295 - policy_loss: 2.0601 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4361 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss did not improve from 2.05536\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8295 - policy_loss: 2.0601 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4361 - value_mse: 0.1184\n",
            "epoch 364\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8271 - policy_loss: 2.0579 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4428 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 2.05536\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8271 - policy_loss: 2.0579 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4428 - value_mse: 0.1177\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.84415 | Policy loss 2.07512 | Value loss 0.69278 | Policy acc 0.43850 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 365\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8432 - policy_loss: 2.0740 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4398 - value_mse: 0.1186\n",
            "Epoch 00001: policy_loss did not improve from 2.05536\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8432 - policy_loss: 2.0740 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4398 - value_mse: 0.1186\n",
            "epoch 366\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8527 - policy_loss: 2.0833 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4362 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss did not improve from 2.05536\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8527 - policy_loss: 2.0833 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4362 - value_mse: 0.1181\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.84925 | Policy loss 2.08033 | Value loss 0.69280 | Policy acc 0.43890 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 367\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8559 - policy_loss: 2.0867 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4379 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss did not improve from 2.05536\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8559 - policy_loss: 2.0867 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4379 - value_mse: 0.1184\n",
            "epoch 368\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8864 - policy_loss: 2.1173 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4281 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss did not improve from 2.05536\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8864 - policy_loss: 2.1173 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4281 - value_mse: 0.1191\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.83778 | Policy loss 2.06899 | Value loss 0.69281 | Policy acc 0.44000 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 369\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8136 - policy_loss: 2.0448 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4510 - value_mse: 0.1171\n",
            "Epoch 00001: policy_loss improved from 2.05536 to 2.04484, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 2.8136 - policy_loss: 2.0448 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4510 - value_mse: 0.1171\n",
            "epoch 370\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8499 - policy_loss: 2.0811 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4342 - value_mse: 0.1179\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8499 - policy_loss: 2.0811 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4342 - value_mse: 0.1179\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.83939 | Policy loss 2.07073 | Value loss 0.69279 | Policy acc 0.43760 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 371\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8511 - policy_loss: 2.0824 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4379 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8511 - policy_loss: 2.0824 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4379 - value_mse: 0.1181\n",
            "epoch 372\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8307 - policy_loss: 2.0620 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4413 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8307 - policy_loss: 2.0620 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4413 - value_mse: 0.1182\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.83551 | Policy loss 2.06698 | Value loss 0.69278 | Policy acc 0.44040 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 373\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8590 - policy_loss: 2.0903 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4326 - value_mse: 0.1190\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8590 - policy_loss: 2.0903 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4326 - value_mse: 0.1190\n",
            "epoch 374\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8605 - policy_loss: 2.0921 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4319 - value_mse: 0.1179\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8605 - policy_loss: 2.0921 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4319 - value_mse: 0.1179\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.83653 | Policy loss 2.06813 | Value loss 0.69278 | Policy acc 0.44160 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 375\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8382 - policy_loss: 2.0693 - value_loss: 0.6933 - policy_categorical_accuracy: 0.4342 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8382 - policy_loss: 2.0693 - value_loss: 0.6933 - policy_categorical_accuracy: 0.4342 - value_mse: 0.1185\n",
            "epoch 376\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8292 - policy_loss: 2.0608 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4350 - value_mse: 0.1178\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8292 - policy_loss: 2.0608 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4350 - value_mse: 0.1178\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.83439 | Policy loss 2.06609 | Value loss 0.69279 | Policy acc 0.43950 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 377\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8207 - policy_loss: 2.0522 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4458 - value_mse: 0.1186\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8207 - policy_loss: 2.0522 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4458 - value_mse: 0.1186\n",
            "epoch 378\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8406 - policy_loss: 2.0724 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4378 - value_mse: 0.1210\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8406 - policy_loss: 2.0724 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4378 - value_mse: 0.1210\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.83563 | Policy loss 2.06741 | Value loss 0.69278 | Policy acc 0.44120 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 379\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8171 - policy_loss: 2.0490 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4428 - value_mse: 0.1170\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8171 - policy_loss: 2.0490 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4428 - value_mse: 0.1170\n",
            "epoch 380\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8356 - policy_loss: 2.0673 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4370 - value_mse: 0.1165\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.8356 - policy_loss: 2.0673 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4370 - value_mse: 0.1165\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.82737 | Policy loss 2.05927 | Value loss 0.69278 | Policy acc 0.44160 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 381\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8445 - policy_loss: 2.0762 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4295 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8445 - policy_loss: 2.0762 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4295 - value_mse: 0.1185\n",
            "epoch 382\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8368 - policy_loss: 2.0689 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4342 - value_mse: 0.1193\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8368 - policy_loss: 2.0689 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4342 - value_mse: 0.1193\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.83475 | Policy loss 2.06681 | Value loss 0.69276 | Policy acc 0.44210 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 383\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8478 - policy_loss: 2.0795 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4402 - value_mse: 0.1168\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.8478 - policy_loss: 2.0795 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4402 - value_mse: 0.1168\n",
            "epoch 384\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8330 - policy_loss: 2.0648 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4341 - value_mse: 0.1170\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8330 - policy_loss: 2.0648 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4341 - value_mse: 0.1170\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.83051 | Policy loss 2.06265 | Value loss 0.69279 | Policy acc 0.44400 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 385\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8249 - policy_loss: 2.0570 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4435 - value_mse: 0.1165\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8249 - policy_loss: 2.0570 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4435 - value_mse: 0.1165\n",
            "epoch 386\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8243 - policy_loss: 2.0563 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4412 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8243 - policy_loss: 2.0563 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4412 - value_mse: 0.1191\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.82426 | Policy loss 2.05650 | Value loss 0.69278 | Policy acc 0.44640 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 387\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8185 - policy_loss: 2.0507 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4391 - value_mse: 0.1175\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8185 - policy_loss: 2.0507 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4391 - value_mse: 0.1175\n",
            "epoch 388\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8241 - policy_loss: 2.0563 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4476 - value_mse: 0.1187\n",
            "Epoch 00001: policy_loss did not improve from 2.04484\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8241 - policy_loss: 2.0563 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4476 - value_mse: 0.1187\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.82562 | Policy loss 2.05797 | Value loss 0.69277 | Policy acc 0.44150 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 389\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8066 - policy_loss: 2.0386 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4443 - value_mse: 0.1178\n",
            "Epoch 00001: policy_loss improved from 2.04484 to 2.03857, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 2.8066 - policy_loss: 2.0386 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4443 - value_mse: 0.1178\n",
            "epoch 390\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8455 - policy_loss: 2.0777 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4329 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss did not improve from 2.03857\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8455 - policy_loss: 2.0777 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4329 - value_mse: 0.1181\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.82477 | Policy loss 2.05716 | Value loss 0.69279 | Policy acc 0.44010 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 391\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8234 - policy_loss: 2.0557 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4443 - value_mse: 0.1183\n",
            "Epoch 00001: policy_loss did not improve from 2.03857\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8234 - policy_loss: 2.0557 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4443 - value_mse: 0.1183\n",
            "epoch 392\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8287 - policy_loss: 2.0610 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4373 - value_mse: 0.1193\n",
            "Epoch 00001: policy_loss did not improve from 2.03857\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8287 - policy_loss: 2.0610 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4373 - value_mse: 0.1193\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.82349 | Policy loss 2.05599 | Value loss 0.69279 | Policy acc 0.44400 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 393\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8462 - policy_loss: 2.0786 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4341 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss did not improve from 2.03857\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8462 - policy_loss: 2.0786 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4341 - value_mse: 0.1191\n",
            "epoch 394\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8599 - policy_loss: 2.0924 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4389 - value_mse: 0.1195\n",
            "Epoch 00001: policy_loss did not improve from 2.03857\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.8599 - policy_loss: 2.0924 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4389 - value_mse: 0.1195\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.82346 | Policy loss 2.05603 | Value loss 0.69279 | Policy acc 0.44260 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 395\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8146 - policy_loss: 2.0472 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4425 - value_mse: 0.1189\n",
            "Epoch 00001: policy_loss did not improve from 2.03857\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8146 - policy_loss: 2.0472 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4425 - value_mse: 0.1189\n",
            "epoch 396\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8452 - policy_loss: 2.0776 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4379 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 2.03857\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8452 - policy_loss: 2.0776 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4379 - value_mse: 0.1182\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.82182 | Policy loss 2.05449 | Value loss 0.69279 | Policy acc 0.44040 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 397\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8355 - policy_loss: 2.0678 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4333 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss did not improve from 2.03857\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8355 - policy_loss: 2.0678 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4333 - value_mse: 0.1181\n",
            "epoch 398\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8388 - policy_loss: 2.0714 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4408 - value_mse: 0.1188\n",
            "Epoch 00001: policy_loss did not improve from 2.03857\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8388 - policy_loss: 2.0714 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4408 - value_mse: 0.1188\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.82206 | Policy loss 2.05482 | Value loss 0.69280 | Policy acc 0.44440 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 399\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8554 - policy_loss: 2.0879 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4331 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 2.03857\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.8554 - policy_loss: 2.0879 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4331 - value_mse: 0.1177\n",
            "epoch 400\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7940 - policy_loss: 2.0265 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4471 - value_mse: 0.1168\n",
            "Epoch 00001: policy_loss improved from 2.03857 to 2.02653, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 2.7940 - policy_loss: 2.0265 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4471 - value_mse: 0.1168\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.81342 | Policy loss 2.04626 | Value loss 0.69280 | Policy acc 0.44280 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 401\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8114 - policy_loss: 2.0441 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4382 - value_mse: 0.1187\n",
            "Epoch 00001: policy_loss did not improve from 2.02653\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8114 - policy_loss: 2.0441 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4382 - value_mse: 0.1187\n",
            "epoch 402\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8395 - policy_loss: 2.0722 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4448 - value_mse: 0.1180\n",
            "Epoch 00001: policy_loss did not improve from 2.02653\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.8395 - policy_loss: 2.0722 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4448 - value_mse: 0.1180\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.82067 | Policy loss 2.05359 | Value loss 0.69281 | Policy acc 0.44350 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 403\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8254 - policy_loss: 2.0582 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4385 - value_mse: 0.1198\n",
            "Epoch 00001: policy_loss did not improve from 2.02653\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8254 - policy_loss: 2.0582 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4385 - value_mse: 0.1198\n",
            "epoch 404\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8343 - policy_loss: 2.0671 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4432 - value_mse: 0.1175\n",
            "Epoch 00001: policy_loss did not improve from 2.02653\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.8343 - policy_loss: 2.0671 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4432 - value_mse: 0.1175\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.81615 | Policy loss 2.04915 | Value loss 0.69280 | Policy acc 0.44200 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 405\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7977 - policy_loss: 2.0306 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4462 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 2.02653\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7977 - policy_loss: 2.0306 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4462 - value_mse: 0.1177\n",
            "epoch 406\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8527 - policy_loss: 2.0858 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4303 - value_mse: 0.1174\n",
            "Epoch 00001: policy_loss did not improve from 2.02653\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.8527 - policy_loss: 2.0858 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4303 - value_mse: 0.1174\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.81512 | Policy loss 2.04821 | Value loss 0.69279 | Policy acc 0.44410 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 407\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8091 - policy_loss: 2.0420 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4429 - value_mse: 0.1188\n",
            "Epoch 00001: policy_loss did not improve from 2.02653\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8091 - policy_loss: 2.0420 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4429 - value_mse: 0.1188\n",
            "epoch 408\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8295 - policy_loss: 2.0624 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4393 - value_mse: 0.1195\n",
            "Epoch 00001: policy_loss did not improve from 2.02653\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8295 - policy_loss: 2.0624 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4393 - value_mse: 0.1195\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.81338 | Policy loss 2.04655 | Value loss 0.69280 | Policy acc 0.44480 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 409\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8108 - policy_loss: 2.0437 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4419 - value_mse: 0.1174\n",
            "Epoch 00001: policy_loss did not improve from 2.02653\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.8108 - policy_loss: 2.0437 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4419 - value_mse: 0.1174\n",
            "epoch 410\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8429 - policy_loss: 2.0758 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4364 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss did not improve from 2.02653\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.8429 - policy_loss: 2.0758 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4364 - value_mse: 0.1184\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.81310 | Policy loss 2.04633 | Value loss 0.69280 | Policy acc 0.44370 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 411\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8468 - policy_loss: 2.0798 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4353 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss did not improve from 2.02653\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8468 - policy_loss: 2.0798 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4353 - value_mse: 0.1185\n",
            "epoch 412\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8070 - policy_loss: 2.0401 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4404 - value_mse: 0.1207\n",
            "Epoch 00001: policy_loss did not improve from 2.02653\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8070 - policy_loss: 2.0401 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4404 - value_mse: 0.1207\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.80727 | Policy loss 2.04056 | Value loss 0.69281 | Policy acc 0.44410 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 413\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7946 - policy_loss: 2.0278 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4462 - value_mse: 0.1186\n",
            "Epoch 00001: policy_loss did not improve from 2.02653\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7946 - policy_loss: 2.0278 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4462 - value_mse: 0.1186\n",
            "epoch 414\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8039 - policy_loss: 2.0370 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4468 - value_mse: 0.1190\n",
            "Epoch 00001: policy_loss did not improve from 2.02653\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8039 - policy_loss: 2.0370 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4468 - value_mse: 0.1190\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.80789 | Policy loss 2.04125 | Value loss 0.69281 | Policy acc 0.44380 | Value MSE 0.11723 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 415\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8018 - policy_loss: 2.0352 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4452 - value_mse: 0.1174\n",
            "Epoch 00001: policy_loss did not improve from 2.02653\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8018 - policy_loss: 2.0352 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4452 - value_mse: 0.1174\n",
            "epoch 416\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8276 - policy_loss: 2.0610 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4410 - value_mse: 0.1193\n",
            "Epoch 00001: policy_loss did not improve from 2.02653\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8276 - policy_loss: 2.0610 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4410 - value_mse: 0.1193\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.80430 | Policy loss 2.03775 | Value loss 0.69279 | Policy acc 0.44640 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 417\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8330 - policy_loss: 2.0661 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4404 - value_mse: 0.1176\n",
            "Epoch 00001: policy_loss did not improve from 2.02653\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8330 - policy_loss: 2.0661 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4404 - value_mse: 0.1176\n",
            "epoch 418\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7952 - policy_loss: 2.0287 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4472 - value_mse: 0.1183\n",
            "Epoch 00001: policy_loss did not improve from 2.02653\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7952 - policy_loss: 2.0287 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4472 - value_mse: 0.1183\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.80509 | Policy loss 2.03859 | Value loss 0.69280 | Policy acc 0.44430 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 419\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7788 - policy_loss: 2.0124 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4512 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss improved from 2.02653 to 2.01239, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 2.7788 - policy_loss: 2.0124 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4512 - value_mse: 0.1191\n",
            "epoch 420\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8069 - policy_loss: 2.0404 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4463 - value_mse: 0.1183\n",
            "Epoch 00001: policy_loss did not improve from 2.01239\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.8069 - policy_loss: 2.0404 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4463 - value_mse: 0.1183\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.80098 | Policy loss 2.03456 | Value loss 0.69279 | Policy acc 0.44900 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 421\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8059 - policy_loss: 2.0394 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4463 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 2.01239\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8059 - policy_loss: 2.0394 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4463 - value_mse: 0.1182\n",
            "epoch 422\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8375 - policy_loss: 2.0711 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4322 - value_mse: 0.1171\n",
            "Epoch 00001: policy_loss did not improve from 2.01239\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.8375 - policy_loss: 2.0711 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4322 - value_mse: 0.1171\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.80339 | Policy loss 2.03702 | Value loss 0.69278 | Policy acc 0.44390 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 423\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8145 - policy_loss: 2.0476 - value_loss: 0.6933 - policy_categorical_accuracy: 0.4418 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 2.01239\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8145 - policy_loss: 2.0476 - value_loss: 0.6933 - policy_categorical_accuracy: 0.4418 - value_mse: 0.1182\n",
            "epoch 424\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8113 - policy_loss: 2.0444 - value_loss: 0.6934 - policy_categorical_accuracy: 0.4428 - value_mse: 0.1183\n",
            "Epoch 00001: policy_loss did not improve from 2.01239\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8113 - policy_loss: 2.0444 - value_loss: 0.6934 - policy_categorical_accuracy: 0.4428 - value_mse: 0.1183\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.79985 | Policy loss 2.03353 | Value loss 0.69280 | Policy acc 0.44570 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 425\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8013 - policy_loss: 2.0346 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4420 - value_mse: 0.1175\n",
            "Epoch 00001: policy_loss did not improve from 2.01239\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8013 - policy_loss: 2.0346 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4420 - value_mse: 0.1175\n",
            "epoch 426\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7986 - policy_loss: 2.0324 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4483 - value_mse: 0.1194\n",
            "Epoch 00001: policy_loss did not improve from 2.01239\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7986 - policy_loss: 2.0324 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4483 - value_mse: 0.1194\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.80048 | Policy loss 2.03422 | Value loss 0.69280 | Policy acc 0.44710 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 427\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7676 - policy_loss: 2.0013 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4495 - value_mse: 0.1176\n",
            "Epoch 00001: policy_loss improved from 2.01239 to 2.00130, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 2.7676 - policy_loss: 2.0013 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4495 - value_mse: 0.1176\n",
            "epoch 428\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8039 - policy_loss: 2.0376 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4502 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 2.00130\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8039 - policy_loss: 2.0376 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4502 - value_mse: 0.1177\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.79742 | Policy loss 2.03120 | Value loss 0.69279 | Policy acc 0.44540 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 429\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8105 - policy_loss: 2.0440 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4439 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 2.00130\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.8105 - policy_loss: 2.0440 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4439 - value_mse: 0.1182\n",
            "epoch 430\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7968 - policy_loss: 2.0306 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4509 - value_mse: 0.1164\n",
            "Epoch 00001: policy_loss did not improve from 2.00130\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7968 - policy_loss: 2.0306 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4509 - value_mse: 0.1164\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.79823 | Policy loss 2.03207 | Value loss 0.69279 | Policy acc 0.44650 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 431\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8118 - policy_loss: 2.0454 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4378 - value_mse: 0.1166\n",
            "Epoch 00001: policy_loss did not improve from 2.00130\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8118 - policy_loss: 2.0454 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4378 - value_mse: 0.1166\n",
            "epoch 432\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7835 - policy_loss: 2.0173 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4439 - value_mse: 0.1202\n",
            "Epoch 00001: policy_loss did not improve from 2.00130\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7835 - policy_loss: 2.0173 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4439 - value_mse: 0.1202\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.79745 | Policy loss 2.03133 | Value loss 0.69279 | Policy acc 0.44610 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 433\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8236 - policy_loss: 2.0572 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4472 - value_mse: 0.1175\n",
            "Epoch 00001: policy_loss did not improve from 2.00130\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8236 - policy_loss: 2.0572 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4472 - value_mse: 0.1175\n",
            "epoch 434\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7866 - policy_loss: 2.0203 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4417 - value_mse: 0.1200\n",
            "Epoch 00001: policy_loss did not improve from 2.00130\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.7866 - policy_loss: 2.0203 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4417 - value_mse: 0.1200\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.79587 | Policy loss 2.02979 | Value loss 0.69279 | Policy acc 0.44630 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 435\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8296 - policy_loss: 2.0635 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4402 - value_mse: 0.1192\n",
            "Epoch 00001: policy_loss did not improve from 2.00130\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8296 - policy_loss: 2.0635 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4402 - value_mse: 0.1192\n",
            "epoch 436\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8247 - policy_loss: 2.0586 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4358 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss did not improve from 2.00130\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.8247 - policy_loss: 2.0586 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4358 - value_mse: 0.1185\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.79528 | Policy loss 2.02925 | Value loss 0.69279 | Policy acc 0.44450 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 437\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7645 - policy_loss: 1.9983 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4492 - value_mse: 0.1187\n",
            "Epoch 00001: policy_loss improved from 2.00130 to 1.99827, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 2.7645 - policy_loss: 1.9983 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4492 - value_mse: 0.1187\n",
            "epoch 438\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8319 - policy_loss: 2.0661 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4390 - value_mse: 0.1193\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8319 - policy_loss: 2.0661 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4390 - value_mse: 0.1193\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.79680 | Policy loss 2.03082 | Value loss 0.69279 | Policy acc 0.44600 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 439\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7840 - policy_loss: 2.0180 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4505 - value_mse: 0.1172\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7840 - policy_loss: 2.0180 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4505 - value_mse: 0.1172\n",
            "epoch 440\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8086 - policy_loss: 2.0426 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4451 - value_mse: 0.1172\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.8086 - policy_loss: 2.0426 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4451 - value_mse: 0.1172\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.79619 | Policy loss 2.03025 | Value loss 0.69278 | Policy acc 0.44380 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 441\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7760 - policy_loss: 2.0100 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4531 - value_mse: 0.1180\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.7760 - policy_loss: 2.0100 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4531 - value_mse: 0.1180\n",
            "epoch 442\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8031 - policy_loss: 2.0371 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4434 - value_mse: 0.1179\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.8031 - policy_loss: 2.0371 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4434 - value_mse: 0.1179\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.79391 | Policy loss 2.02801 | Value loss 0.69278 | Policy acc 0.44500 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 443\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7899 - policy_loss: 2.0240 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4523 - value_mse: 0.1165\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.7899 - policy_loss: 2.0240 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4523 - value_mse: 0.1165\n",
            "epoch 444\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7712 - policy_loss: 2.0052 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4498 - value_mse: 0.1182\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.7712 - policy_loss: 2.0052 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4498 - value_mse: 0.1182\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.79450 | Policy loss 2.02863 | Value loss 0.69278 | Policy acc 0.44550 | Value MSE 0.11721 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 445\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7806 - policy_loss: 2.0146 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4466 - value_mse: 0.1172\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.7806 - policy_loss: 2.0146 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4466 - value_mse: 0.1172\n",
            "epoch 446\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7991 - policy_loss: 2.0330 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4481 - value_mse: 0.1170\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.7991 - policy_loss: 2.0330 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4481 - value_mse: 0.1170\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.79196 | Policy loss 2.02612 | Value loss 0.69278 | Policy acc 0.44450 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 447\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8203 - policy_loss: 2.0543 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4416 - value_mse: 0.1208\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.8203 - policy_loss: 2.0543 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4416 - value_mse: 0.1208\n",
            "epoch 448\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7975 - policy_loss: 2.0315 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4438 - value_mse: 0.1205\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.7975 - policy_loss: 2.0315 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4438 - value_mse: 0.1205\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.79185 | Policy loss 2.02604 | Value loss 0.69278 | Policy acc 0.44790 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 449\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8090 - policy_loss: 2.0431 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4440 - value_mse: 0.1201\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.8090 - policy_loss: 2.0431 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4440 - value_mse: 0.1201\n",
            "epoch 450\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8036 - policy_loss: 2.0377 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4455 - value_mse: 0.1190\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.8036 - policy_loss: 2.0377 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4455 - value_mse: 0.1190\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.79208 | Policy loss 2.02631 | Value loss 0.69278 | Policy acc 0.44730 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 451\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7961 - policy_loss: 2.0301 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4448 - value_mse: 0.1186\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.7961 - policy_loss: 2.0301 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4448 - value_mse: 0.1186\n",
            "epoch 452\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7971 - policy_loss: 2.0315 - value_loss: 0.6926 - policy_categorical_accuracy: 0.4503 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.7971 - policy_loss: 2.0315 - value_loss: 0.6926 - policy_categorical_accuracy: 0.4503 - value_mse: 0.1184\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78996 | Policy loss 2.02421 | Value loss 0.69278 | Policy acc 0.44570 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 453\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7886 - policy_loss: 2.0229 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4493 - value_mse: 0.1187\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 221ms/step - loss: 2.7886 - policy_loss: 2.0229 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4493 - value_mse: 0.1187\n",
            "epoch 454\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8369 - policy_loss: 2.0709 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4378 - value_mse: 0.1194\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.8369 - policy_loss: 2.0709 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4378 - value_mse: 0.1194\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.79019 | Policy loss 2.02446 | Value loss 0.69278 | Policy acc 0.44760 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 455\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7973 - policy_loss: 2.0315 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4467 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7973 - policy_loss: 2.0315 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4467 - value_mse: 0.1177\n",
            "epoch 456\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7990 - policy_loss: 2.0331 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4451 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.7990 - policy_loss: 2.0331 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4451 - value_mse: 0.1191\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.79085 | Policy loss 2.02515 | Value loss 0.69278 | Policy acc 0.44500 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 457\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7862 - policy_loss: 2.0203 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4495 - value_mse: 0.1173\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.7862 - policy_loss: 2.0203 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4495 - value_mse: 0.1173\n",
            "epoch 458\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7717 - policy_loss: 2.0059 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4486 - value_mse: 0.1207\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.7717 - policy_loss: 2.0059 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4486 - value_mse: 0.1207\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78904 | Policy loss 2.02336 | Value loss 0.69278 | Policy acc 0.44630 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 459\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7740 - policy_loss: 2.0083 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4441 - value_mse: 0.1192\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.7740 - policy_loss: 2.0083 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4441 - value_mse: 0.1192\n",
            "epoch 460\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8007 - policy_loss: 2.0348 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4506 - value_mse: 0.1173\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.8007 - policy_loss: 2.0348 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4506 - value_mse: 0.1173\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78863 | Policy loss 2.02297 | Value loss 0.69278 | Policy acc 0.44630 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 461\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7843 - policy_loss: 2.0184 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4471 - value_mse: 0.1188\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.7843 - policy_loss: 2.0184 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4471 - value_mse: 0.1188\n",
            "epoch 462\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7947 - policy_loss: 2.0288 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4410 - value_mse: 0.1202\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.7947 - policy_loss: 2.0288 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4410 - value_mse: 0.1202\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78826 | Policy loss 2.02261 | Value loss 0.69278 | Policy acc 0.44660 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 463\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7891 - policy_loss: 2.0232 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4466 - value_mse: 0.1185\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.7891 - policy_loss: 2.0232 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4466 - value_mse: 0.1185\n",
            "epoch 464\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7694 - policy_loss: 2.0036 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4471 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.7694 - policy_loss: 2.0036 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4471 - value_mse: 0.1181\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78789 | Policy loss 2.02226 | Value loss 0.69278 | Policy acc 0.44570 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 465\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7814 - policy_loss: 2.0158 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4487 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.7814 - policy_loss: 2.0158 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4487 - value_mse: 0.1181\n",
            "epoch 466\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7723 - policy_loss: 2.0067 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4486 - value_mse: 0.1179\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 222ms/step - loss: 2.7723 - policy_loss: 2.0067 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4486 - value_mse: 0.1179\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78764 | Policy loss 2.02202 | Value loss 0.69278 | Policy acc 0.44500 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 467\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7838 - policy_loss: 2.0179 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4468 - value_mse: 0.1193\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7838 - policy_loss: 2.0179 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4468 - value_mse: 0.1193\n",
            "epoch 468\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7985 - policy_loss: 2.0327 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4430 - value_mse: 0.1181\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7985 - policy_loss: 2.0327 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4430 - value_mse: 0.1181\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78689 | Policy loss 2.02128 | Value loss 0.69278 | Policy acc 0.44640 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 469\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8032 - policy_loss: 2.0376 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4401 - value_mse: 0.1202\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.8032 - policy_loss: 2.0376 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4401 - value_mse: 0.1202\n",
            "epoch 470\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7659 - policy_loss: 2.0001 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4496 - value_mse: 0.1172\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7659 - policy_loss: 2.0001 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4496 - value_mse: 0.1172\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78660 | Policy loss 2.02100 | Value loss 0.69278 | Policy acc 0.44750 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 471\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8175 - policy_loss: 2.0515 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4381 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8175 - policy_loss: 2.0515 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4381 - value_mse: 0.1177\n",
            "epoch 472\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8297 - policy_loss: 2.0640 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4387 - value_mse: 0.1200\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8297 - policy_loss: 2.0640 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4387 - value_mse: 0.1200\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78677 | Policy loss 2.02118 | Value loss 0.69278 | Policy acc 0.44690 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 473\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8201 - policy_loss: 2.0546 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4390 - value_mse: 0.1200\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8201 - policy_loss: 2.0546 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4390 - value_mse: 0.1200\n",
            "epoch 474\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8010 - policy_loss: 2.0351 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4384 - value_mse: 0.1201\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8010 - policy_loss: 2.0351 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4384 - value_mse: 0.1201\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78653 | Policy loss 2.02095 | Value loss 0.69278 | Policy acc 0.44650 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 475\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7873 - policy_loss: 2.0211 - value_loss: 0.6933 - policy_categorical_accuracy: 0.4442 - value_mse: 0.1176\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7873 - policy_loss: 2.0211 - value_loss: 0.6933 - policy_categorical_accuracy: 0.4442 - value_mse: 0.1176\n",
            "epoch 476\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7829 - policy_loss: 2.0173 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4462 - value_mse: 0.1189\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.7829 - policy_loss: 2.0173 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4462 - value_mse: 0.1189\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78641 | Policy loss 2.02084 | Value loss 0.69278 | Policy acc 0.44790 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 477\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8044 - policy_loss: 2.0386 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4399 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8044 - policy_loss: 2.0386 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4399 - value_mse: 0.1177\n",
            "epoch 478\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7799 - policy_loss: 2.0144 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4461 - value_mse: 0.1184\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.7799 - policy_loss: 2.0144 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4461 - value_mse: 0.1184\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78657 | Policy loss 2.02101 | Value loss 0.69278 | Policy acc 0.44730 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 479\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7978 - policy_loss: 2.0320 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4478 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7978 - policy_loss: 2.0320 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4478 - value_mse: 0.1177\n",
            "epoch 480\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7731 - policy_loss: 2.0076 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4522 - value_mse: 0.1197\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.7731 - policy_loss: 2.0076 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4522 - value_mse: 0.1197\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78592 | Policy loss 2.02035 | Value loss 0.69278 | Policy acc 0.44920 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 481\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8014 - policy_loss: 2.0357 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4427 - value_mse: 0.1179\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8014 - policy_loss: 2.0357 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4427 - value_mse: 0.1179\n",
            "epoch 482\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7733 - policy_loss: 2.0074 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4474 - value_mse: 0.1186\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.7733 - policy_loss: 2.0074 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4474 - value_mse: 0.1186\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78546 | Policy loss 2.01990 | Value loss 0.69278 | Policy acc 0.44810 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 483\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8002 - policy_loss: 2.0347 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4510 - value_mse: 0.1189\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8002 - policy_loss: 2.0347 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4510 - value_mse: 0.1189\n",
            "epoch 484\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7847 - policy_loss: 2.0189 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4432 - value_mse: 0.1167\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.7847 - policy_loss: 2.0189 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4432 - value_mse: 0.1167\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78539 | Policy loss 2.01984 | Value loss 0.69278 | Policy acc 0.44850 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 485\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7771 - policy_loss: 2.0114 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4493 - value_mse: 0.1176\n",
            "Epoch 00001: policy_loss did not improve from 1.99827\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7771 - policy_loss: 2.0114 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4493 - value_mse: 0.1176\n",
            "epoch 486\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7611 - policy_loss: 1.9953 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4579 - value_mse: 0.1190\n",
            "Epoch 00001: policy_loss improved from 1.99827 to 1.99531, saving model to /content/drive/MyDrive/DeepGo/Mikail_DUZENLI_Mixed_architecture_VF.h5\n",
            "157/157 [==============================] - 36s 232ms/step - loss: 2.7611 - policy_loss: 1.9953 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4579 - value_mse: 0.1190\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78538 | Policy loss 2.01983 | Value loss 0.69278 | Policy acc 0.44900 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 487\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7770 - policy_loss: 2.0114 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4545 - value_mse: 0.1177\n",
            "Epoch 00001: policy_loss did not improve from 1.99531\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7770 - policy_loss: 2.0114 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4545 - value_mse: 0.1177\n",
            "epoch 488\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8051 - policy_loss: 2.0397 - value_loss: 0.6926 - policy_categorical_accuracy: 0.4425 - value_mse: 0.1176\n",
            "Epoch 00001: policy_loss did not improve from 1.99531\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.8051 - policy_loss: 2.0397 - value_loss: 0.6926 - policy_categorical_accuracy: 0.4425 - value_mse: 0.1176\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78556 | Policy loss 2.02002 | Value loss 0.69278 | Policy acc 0.44850 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 489\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7951 - policy_loss: 2.0295 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4433 - value_mse: 0.1174\n",
            "Epoch 00001: policy_loss did not improve from 1.99531\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7951 - policy_loss: 2.0295 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4433 - value_mse: 0.1174\n",
            "epoch 490\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7711 - policy_loss: 2.0057 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4479 - value_mse: 0.1160\n",
            "Epoch 00001: policy_loss did not improve from 1.99531\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7711 - policy_loss: 2.0057 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4479 - value_mse: 0.1160\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78532 | Policy loss 2.01977 | Value loss 0.69278 | Policy acc 0.44880 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 491\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7805 - policy_loss: 2.0148 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4516 - value_mse: 0.1172\n",
            "Epoch 00001: policy_loss did not improve from 1.99531\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7805 - policy_loss: 2.0148 - value_loss: 0.6929 - policy_categorical_accuracy: 0.4516 - value_mse: 0.1172\n",
            "epoch 492\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7856 - policy_loss: 2.0197 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4450 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss did not improve from 1.99531\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.7856 - policy_loss: 2.0197 - value_loss: 0.6932 - policy_categorical_accuracy: 0.4450 - value_mse: 0.1191\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78530 | Policy loss 2.01975 | Value loss 0.69278 | Policy acc 0.44890 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 493\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7944 - policy_loss: 2.0289 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4507 - value_mse: 0.1172\n",
            "Epoch 00001: policy_loss did not improve from 1.99531\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7944 - policy_loss: 2.0289 - value_loss: 0.6927 - policy_categorical_accuracy: 0.4507 - value_mse: 0.1172\n",
            "epoch 494\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7939 - policy_loss: 2.0283 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4414 - value_mse: 0.1191\n",
            "Epoch 00001: policy_loss did not improve from 1.99531\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.7939 - policy_loss: 2.0283 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4414 - value_mse: 0.1191\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78506 | Policy loss 2.01951 | Value loss 0.69278 | Policy acc 0.44860 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 495\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7948 - policy_loss: 2.0293 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4395 - value_mse: 0.1190\n",
            "Epoch 00001: policy_loss did not improve from 1.99531\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7948 - policy_loss: 2.0293 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4395 - value_mse: 0.1190\n",
            "epoch 496\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8087 - policy_loss: 2.0432 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4412 - value_mse: 0.1167\n",
            "Epoch 00001: policy_loss did not improve from 1.99531\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.8087 - policy_loss: 2.0432 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4412 - value_mse: 0.1167\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78536 | Policy loss 2.01982 | Value loss 0.69278 | Policy acc 0.44920 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 497\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7982 - policy_loss: 2.0324 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4482 - value_mse: 0.1174\n",
            "Epoch 00001: policy_loss did not improve from 1.99531\n",
            "157/157 [==============================] - 35s 223ms/step - loss: 2.7982 - policy_loss: 2.0324 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4482 - value_mse: 0.1174\n",
            "epoch 498\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7906 - policy_loss: 2.0248 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4507 - value_mse: 0.1178\n",
            "Epoch 00001: policy_loss did not improve from 1.99531\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.7906 - policy_loss: 2.0248 - value_loss: 0.6930 - policy_categorical_accuracy: 0.4507 - value_mse: 0.1178\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78522 | Policy loss 2.01968 | Value loss 0.69278 | Policy acc 0.44900 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n",
            "epoch 499\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.7955 - policy_loss: 2.0299 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4454 - value_mse: 0.1171\n",
            "Epoch 00001: policy_loss did not improve from 1.99531\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.7955 - policy_loss: 2.0299 - value_loss: 0.6928 - policy_categorical_accuracy: 0.4454 - value_mse: 0.1171\n",
            "epoch 500\n",
            "157/157 [==============================] - ETA: 0s - loss: 2.8110 - policy_loss: 2.0452 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4444 - value_mse: 0.1208\n",
            "Epoch 00001: policy_loss did not improve from 1.99531\n",
            "157/157 [==============================] - 35s 224ms/step - loss: 2.8110 - policy_loss: 2.0452 - value_loss: 0.6931 - policy_categorical_accuracy: 0.4444 - value_mse: 0.1208\n",
            "------------------------------------------------------------------------------------------------------------\n",
            "Loss 2.78517 | Policy loss 2.01962 | Value loss 0.69278 | Policy acc 0.44920 | Value MSE 0.11722 \n",
            "------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "T_max=501\n",
        "eta_max=1e-3\n",
        "eta_min=1e-7\n",
        "\n",
        "for epoch in range (1, T_max):\n",
        "    print ('epoch ' + str (epoch))\n",
        "    golois.getBatch(input_data, policy, value, end, groups, epoch * N)\n",
        "    lr = eta_min + (eta_max - eta_min) * (1 + np.cos(np.pi * epoch / T_max)) / 2\n",
        "    K.set_value(model.optimizer.learning_rate, lr)\n",
        "    history = model.fit(input_data,\n",
        "                        {'policy': policy, 'value': value}, \n",
        "                        epochs=1, batch_size=batch,callbacks=callbacks)\n",
        "    \n",
        "    if (epoch % 5 == 0):\n",
        "        gc.collect ()\n",
        "    if (epoch % 2 == 0):\n",
        "        golois.getValidation (input_data, policy, value, end)\n",
        "        val = model.evaluate (input_data,\n",
        "                              [policy, value], verbose = 0, batch_size=batch)\n",
        "        print('------------------------------------------------------------------------------------------------------------')\n",
        "        print (f\"Loss {val[0]:.5f} | Policy loss {val[1]:.5f} | Value loss {val[2]:.5f} | Policy acc {val[3]:.5f} | Value MSE {val[4]:.5f} \")\n",
        "        print('------------------------------------------------------------------------------------------------------------')\n",
        "        history_acc.append(val[3])\n",
        "        history_lr.append(lr)\n",
        "        history_MSE.append(val[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-P40vJq3yeDe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "05ed4a7d-5ebb-4121-9c0d-14678f285b93"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.plot(np.arange(1,501,2), history_acc)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "a3b9fe1c-e19c-42c2-aedd-f61b211d7d6b",
        "id": "JJMwq6A9FDM5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.plot(np.arange(1,501,2), history_MSE)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX0oNUfI32-8"
      },
      "outputs": [],
      "source": [
        "raise SystemExit(\"Stop right there!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Load and test a model here**"
      ],
      "metadata": {
        "id": "guMa3kHimaaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = '//content/drive/MyDrive/DeepGo/Mikail_Mixed_architecture_V4.h5'"
      ],
      "metadata": {
        "id": "CQEszJBCqMnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_YpFwUph2mv"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "golois.getValidation (input_data, policy, value, end)\n",
        "val = model.evaluate (input_data,[policy, value], verbose = 0, batch_size=batch)\n",
        "print (f\"Loss {val[0]:.5f} | Policy loss {val[1]:.5f} | Value loss {val[2]:.5f} | Policy acc {val[3]:.5f} | Value MSE {val[4]:.5f} \")"
      ],
      "metadata": {
        "id": "i84Y2H0emwbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def list_files(dir):\n",
        "  best_accuracy=0\n",
        "  for mods, dirs, b in os.walk(dir):\n",
        "    print(f'mods {mods}')\n",
        "    for mod in mods:\n",
        "            print()\n",
        "            break\n",
        "            model=keras.models.load_model(mod)\n",
        "            val = model.evaluate (input_data,[policy, value], verbose = 0, batch_size=batch)\n",
        "            print (f\"For model {mod} we have : Loss {val[0]:.5f} | Policy loss {val[1]:.5f} | Value loss {val[2]:.5f} | Policy acc {val[3]:.5f} | Value MSE {val[4]:.5f} \")\n",
        "\n",
        "            if best_accuracy < val[3]:\n",
        "              best_accuracy=val[3]\n",
        "              best_model = model\n",
        "              best_model_dir = mod\n",
        "\n",
        "  print(f'Best model is {best_model_dir}')\n",
        "  return best_model"
      ],
      "metadata": {
        "id": "_gNw9Ilpokgl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "DeepGo_MD.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM9KmHGetKaXIZfXntkaNGt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}